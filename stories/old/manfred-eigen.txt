manfred.eigen

Nobel Prize winning German biophysical chemist, Manfred Eigen (1927-2019), was best known for his work on fast chemical reactions and his development of ways to accurately measure these reactions down to the nearest billionth of a second.  He published over 100 papers with topics ranging from hydrogen bridges of nucleic acids to the storage of information in the central nervous system.

I went to high school, which is called Gymnasium. Gymnasium at that time meant that you start with old languages like Latin...
[Q] Greek...
Greek, yes, and very... not much mathematics and natural sciences, which I liked too. At the same time with ten years they draft you to the youth organisation of the Nazis, and... Jungvolk, but I was lucky, I came into an orchestra, so... which I later even got to organise myself, and we played there classical music all the time and so we had a very good time. The school was no problem. We sometime had a very good mathematics teacher, and I was brilliant in mathematics, then we got a bad teacher and I was lazy...
[Q] Uninterested...
Yes. I mean I was not interested in trivial type of problems. Natural sciences was not very good, although I liked myself chemistry. I had a laboratory at home, and...
[Q] A little box...
No, it was a real laboratory already, which sometimes my mother didn't like it at all when something exploded in the kitchen. That was the time, I remember both my parents told me terrible things about the Nazis. They say they are driving to war, and that was different from what I learnt at school, where they, of course, hailed them, and I had to become fifteen, sixteen years old to find out that my parents were right, but this was already then towards the end of the war.
[Q] So there was a sort of internal or even open opposition from you personally towards your parents, or were you respectful enough not to show? 
Yes. Well, I told them what I heard in school, and they told me that's... they told me also your teachers have to say this, otherwise they will be in prison...
[Q] Out of job... 
Or they will be out of job or so, yes. As a small boy you want to make your experience yourself and, the war started when I was twelve in '39.
[Q] Yes, just a question. Was this discussion every day, or just that you had once a week such a discussion? Did you... did one avoid to talk about it, or do you remember this now a posteriori? Because how you say it, it seems so as if it was every day a problem. 
We always had lunch together, when I came out of school I had to hurry to get home because my father wanted that the family is united at lunch. And of course they often came home, my father, and say they heard something terrible going on and so there was a discussion at the table and we brought stories home from school, yes, but my youth was very much directed towards learning in school, and I liked it also, and towards music.

The first big...
[Q] Crash.
... interruption of this life came when I was fifteen. At that time the bombing of the cities had started and, of course, they got their first... they were not successful any more in the war, and they were short of people, so they drafted the school classes for the anti-aircraft guns.
[Q] What was the limit of age? 
Yes, I was a little bit younger in my class.
[Q] So fifteen was the... 
Usually the people were sixteen years old when the school class draft, but I was only fifteen, at least for another half a year. And so we were drafted to the outside of Bochum to the anti-aircraft gun, were trained there, and since there were many air attacks during the night, and finally also during daytime, there was not much school we had.
[Q] Did you stay at home at that time still, or did you..? 
No, no...
[Q] You slept in a military barrack? 
Barrack, yes, and it was...  yes.
[Q] So it was a soldier life. 
It was a soldier life, and it was rough, I didn't like that!
[Q] Depressing. 
Yes, is the words we were...
[Q] It was a crude time. 
Yes, it was. Of course there's also some enthusiasm about young people first, but that soon...
[Q] Decayed? 
Decayed and disappeared, yes. And, well, finally with seventeen I was also drafted to the airforce, but that was only in the last months of the war.
[Q] But you didn't know at that time that it were the last months of the war. 
No, it was a terrible time I can tell you. At that time we were very clear about the system, and with a friend we said we prepare to escape. But we were finally over...
[Q] Rolled? 
Rolled, yes, by the war. I remember that in April '45 I was a prisoner of war at the Salzburg airport.
[Q] So that means with the... as a soldier you were put down to the south of Germany, Austria, as it was Germany at that time.
Yes, and the war was over.
[Q] And what was your task at that time? What to defend and what to do? 
Nothing. I mean, it was airforce. We were supposed to be trained on planes but there were no planes left then.
[Q] But you were just still in training. 
Oh yes. I mean I was a few months only in that...
[Q] So you were not an active soldier in the sense? Whether indirectly... 
What do you mean by active?
[Q] I mean you were still in the...
Fortunately we didn't have to shoot.
[Q] Ja, that's what I meant. 
Could go back and in Salzburg at the airport we got imprisoned.

At the end of the war on the airport of Salzburg, where we were taken over by American troops, and were supposed to come into a camp, prisoner of war camp, but my friend Werner Bongard and I decided that we escape. And we could manage to do so, and that was just the day the war ended, May 8th maybe a day earlier, and the 9th May was my eighteenth birthday so we were free already but down in southern Germany, and where to go? We wanted to go back to our parents, which is in northern Germany. So we... at that time no trains and nothing was running so we had to walk. And we did so. Thousand kilometres of walking, and we decided... we said to ourselves we probably never will have a chance to walk through Germany. So let's do it in a way that we, if there's something to see, let's do it, not the most direct way but the nicest way, and that's what we did.
We went to the Burg Hohenstaufen and we went up and looked at it and we were friendly accommodated by people, we prevented large cities, we went largely through rural areas which were not much destroyed or so, and we were free. I have wonderful recollections to that month of walking.

I had always the choice either becoming a musician or, in the other case I was sure that I would study mathematics, physics, chemistry, something in that area.  And already as a boy I read much about Göttingen. Göttingen had a wonderful history in the natural sciences.
Now with music, I think that time had passed. As a musician you have to have a repertoire when you are eighteen. You don't have to practice any more, you have to play things, and I hadn't played from my fifteenth year of age any more, now I was eighteen.  So I decided to make music my hobby and to study physics, or even I decided to study physical chemistry.

Together with a friend I went again, only partly by train, to Göttingen in August 1945. And it was true, the university you could inscribe there. Many people of course, coming back from the war, used the chance and came to Göttingen. I remember to get there with a friend, a medical student, and we went first to Hermann Rhein, the physiologist Rhein, was a famous name. Somehow my friend was a relative of him. And so he asked what we wanted to study and what we know already. So in my case he said, 'You should go to Eucken, to Professor Eucken, because what you want to do is physical chemistry'. So I went to Eucken, and Eucken told me, 'You can approach physical chemistry either from chemistry or from physics. So in your case', he said, 'from what I hear from you I would suggest to start with physics'.
So I went over to the Physics Department and it was Professor Becker, the theoretical physicist. He said, 'Yes. But we have so many people, older people, soldiers who missed all the time in the war. You are just eighteen years old and also you have to take your Abitur, your Matura'. Well, I could do that in a direct examination, I didn't have to go to school again. But he said, 'What can we do with you? You are too young. We must first take care of the older students'. But then he said, 'Look, there are not many people who want to study astronomy and geophysics. There are still openings. So why don't you go to the geophysicist and ask whether he would take you? The first two years is physics and your lectures would be the same'.
So I went to Professor Bartels who was a geophysicist - he was a famous geophysicist - Julius Bartels. He asked me immediately, 'Can you build a seismograph?' I hardly knew what a seismograph is, but to be sure I said, 'Yes'. He said 'Oh yes. I can take you'. And I ask, 'Why do you want me to build a seismograph?' He said, 'Well, the English army is going to blow up the island of Helgoland', because that was in the North sea, 'and this is the only chance in northern Germany to record seismic waves because we never have earthquakes here'. So he wanted to build up twenty stations to pick up the seismic waves from that.
Now indeed, I built a seismograph, and it worked even, and I took wonderful waves when they tried to blow up Helgoland. So we got our seismic waves but the island did not...
[Q] Disappear.
It was a little bit destroyed but, as you know, now it's rebuilt, so there is nothing like that. So I was in physics now. I had to listen to some lectures in astronomy in addition to what I had to do in physics, chemistry, mathematics. But it was a wonderful time.

Göttingen indeed has a big tradition in the natural sciences. You know, the University of Göttingen is not really an old university. It was founded in 1738 by the British king, George II, who at the same time was a king of Hannover. And Göttingen is the state university of Hannover... of the kingdom of Hannover. By the way, the same king, in the same year, founded also the University of Princeton, both having a good tradition in natural sciences.
Now, Göttingen then was... immediately became the university of enlightenment and had a very good start, because it was not dominated by church. And so it became the centre of enlightenment in Germany, and especially in mathematics it grew. Karl Friedrich Gauss was appointed Professor of Mathematics and he founded the tradition. Gauss... his successor was Dirichlet, who was married to Rebecca Mendelssohn-Bartholdy, a sister of Felix Mendelssohn-Bartholdy. His successor was Riemann. Riemann geometry came up in Göttingen, and it went on to Hilbert and Klein. Minkowski was in Göttingen, Hilbert, Klein, Weyl, Courant, Landau, Emmy Noether, it was a great time.
So I still got some of these famous mathematicians in my lectures, I heard them - Herglotz, Kaluza. Kaluza has become famous, we didn't know about that work, it became famous later for the five-dimensional geometry, which played some role in elementary particle theory in later years. And, well...
[Q] Rellich?
Rellich was one of my teachers, and...
[Q] Siegel?
And Carl Ludwig Siegel came back, he was immigrated to Princeton but he came back to Göttingen. So that was mathematics, but the tradition of physics was also great in Göttingen. You know, quantum mechanics came out of Göttingen in the '20s, all the famous physicists were at that time there at Göttingen, and now some of the founders of quantum mechanics came to Göttingen.   Heisenberg came early in 1946... came to Göttingen, Max von Laue came, even Max Planck was at Göttingen. He died in 1947. Otto Hahn came to Göttingen, so it was a great time.
We were free. Could you imagine that time after the terrible wartime, we could study, we were hungry for science.

The thesis was 'The specific heat of heavy water'. You know, heavy water is the isotope, the D2O, the deuterium isotope of normal water which is H2O, and Eucken was interested in the specific heat, which had to be measured very precisely by five decimals, up to 10-5, because he had developed the water theory, the theory of the structure formation in water. You know, water molecules are dipoles, and so they have a strong interaction which is called hydrogen bond, it's a bond between the positive proton in the H2O molecule and the lone electron pair at the oxygen of the water molecule, and it made these associations via hydrogen bonds. And he wanted to test his theory and needed the isotope effects.
[Q] But the question is, it was post-war, DO2, heavy water...
D2O...
[Q] Excuse me... did he have it? It was forbidden, it was a... 
Yes, he still had in his board, he still had about 500 grams of it, but it was a...
[Q] Secret? Treasure? 
It was a treasure. I mean he could... well, all right, you couldn't buy it any more, you couldn't get new one, but what you had, you can't do any harm with D2O. D2O plays a role in the atomic reactor, the fast neutrons are slowed down by the deuterium and therefore... But for atomic reactor you needed large amounts of heavy water so you couldn't do anything. No, it was a real scientific problem, but heavy water was expensive at that time.
[Q] And you couldn't buy it? 
Oh no, you couldn't buy it, it wasn't available, and if it were available in the States or wherever, it would have been very, very expensive.

What I had to do was to build a calorimeter. A calorimeter to measure specific heats. You know the specific heat tells you how much energy you have to put into the material to increase the temperature by 1°C. And that amount of heat tells you where the energy is going, it goes into the vibrations, it goes into the rotation and the translation of the molecule, so the specific heat is an indicator of the energy states of the molecule which they can assume. Of course, it also gives a contribution to the interaction among the molecules, especially to the hydrogen bonding, so when you heat up water you break some of the hydrogen bonds and there is a bond energy involved, and so that shows up in the specific heat. That's why Eucken wanted to have measurements of specific heat, and I had to build a calorimeter, which is a very precise instrument. To give you an impression of that, it's a so-called adiabatic calorimeter, which means that the whole vessel containing the heavy water is surrounded by a mantle, and then there is a differential thermocouple which measures the temperature between the inside and the outside, and you regulate the heat at the mantle such that there is no temperature difference between inside and outside, so heat loss cannot occur. That's the adiabatic calorimeter. And to give you an impression, the thermocouple measures a temperature precise by one thousandth of a degree, and the whole measurement went over about 100°C, so hundred and a thousandth, that gives you the five decimals which we needed for the measurement.
Well, I built such an instrument and started my...
[Q] You mean the glass shop built this sophisticated instrument? 
Oh yes, the glass shop and the mechanic machine shop...
[Q] According to your [design]...
The other thing, there'd be the heating which is electric and so on, precise measurements of course, you have to measure very carefully the voltage and the current and so on. But the big question which appeared was, to what temperature can we go? Eucken, of course, wanted to go as high as possible with the temperature, and since the water was melted into the glass vessel, the question is: what pressure does a glass vessel withstand?

Eucken said, 'Now you should measure some electrolyte solutions'. Because you know when, let's say, take sodium chloride, ordinary salt, if you dissolve it in water they split into ions, sodium ions, Na+, and chloride ions, CO-, and these ions surround themselves with a water layer, it's called hydration sphere, that's why the water dipoles interact with the ions, that's clear.  And so, again, like measuring specific heat of water or heavy water and so on, the specific heat of electrolyte solutions gives you information about these hydration processes, and Eucken was also interested in those.

I started my thesis as a diploma thesis, that's like a master thesis in the States. And I told Eucken, 'Look, I measured now the specific heat of heavy water up to...' It came almost to 200°C, we improved the machine later, and I said, 'Now let me first make my examination and then start my doctoral thesis'. 'Oh', he said, 'then we lose several months of time', and, 'why don't you go on immediately?' Well, I mean, he probably knew that he was not living too long any more, and, so, in fact he died after a few months. But I said, 'Look, but I need first my diploma, then I can do my doctors'. 'Oh', he said, 'why do you need a diploma, why don't you continue and I'll take it as a doctoral thesis?' 'Well', I said, 'but that you have to tell your colleagues in the faculty'. He said, 'That's my problem, not yours'.
And so I could immediately go on, and did these other measurements and finished it as a doctoral thesis. So I was really, what is impossible nowadays, was 23... had my doctoral thesis. But Eucken died meanwhile and he left a stipend for me so I stayed on in the Institute of Physical Chemistry.

I should say a few words about physical chemistry in Göttingen. I said that mathematics had a good tradition. I said physics and quantum mechanics came out of Göttingen, and in fact Edward Teller was an assistant with Eucken in 1932, 1933. Viki Weisskopf was assistant in the Institute, but physical chemistry as such had also a good tradition in Göttingen, as did chemistry. You know Wöhler was at Göttingen.
[Q] Wallach.
Wallach was there, and Windaus, all the W's!
[Q] Zsigmondy.
Zsigmondy did his ultramicroscope in Göttingen, yes. And so was physical chemistry. It was founded by Walther Nernst in 1896. He was Professor of Physics in Göttingen and he founded the first Physical Chemistry Institute, and I think it was the first institute of physical chemistry in the world. So the successor of Nernst then was... Nernst later went to Berlin, and his successor was Tammann, who was especially studying metals, and the successor of Tammann was Eucken.
[Q] So I understand Eucken was the doyen of physical chemistry in Göttingen in Germany?
Yes.
[Q] So he was worldwide renown? 
Yes, and he had written a very famous textbook which contained all physics and chemistry which was relevant for physical chemistry, including quantum mechanics, and I think Edward Teller had participated in writing the first volume of it in quite a detailed way.

Nernst was a very authoritative person. There is a nice story perhaps I could tell. Nernst later was somehow in disgrace with the Nazi system but he died during the war and they forbid to have a big funeral ceremony, but some of the professors went secretly and he was buried at his farm which is east of Berlin. And, among them were Bonhoeffer, Karl-Friedrich Bonhoeffer, to whom I later came after Eucken, but I will tell later about that, and Richard Becker, whom I mentioned, who was a theoretical physicist in Göttingen. So, they met, but then when the war came to the end that part of Germany was taken by Russian troops and they brought Nernst over to Thuringia, but then it was decided that also Thuringia was occupied by Russian troops and they brought him to Göttingen.
It happened that in Thuringia again Bonhoeffer and Becker went to a little ceremony and finally, when he came to Göttingen, Bonhoeffer founded the Max Planck Institute in Göttingen, physical chemistry, and Becker was the Professor of Theoretical Physics. And then it happened at the cemetery that Bonhoeffer said to his colleague, Becker, 'Isn't that somehow funny that we bury our colleague Nernst now for the third time?' And Becker said, 'Oh, you can't do it often enough', because Nernst was such a rough person that they all... but that was a joke of course.

I heard that Bonhoeffer founded the Max Planck Institute at Göttingen, so after Eucken died I went to Bonhoeffer and he offered me immediately a position in his institute, but I said I will stay in the old institute until a successor will arrive because the teaching there had to be done and I had to help as an assistant with that.
But I am telling this because I am now coming to one of my main subjects of my scientific career, that's the study of fast reactions, and I should perhaps tell this story. Already when I studied with Eucken, I read in his textbook on physical chemistry...
[Q] May I ask when was this famous book edited?
Oh, I think that... as I say that Teller was involved in the first volume which was 1932, so very early in the thirties the first edition came out. And it was the bible of physical chemistry. There was no comparable textbook in physical chemistry which was as detailed, there were three big volumes of this book. Well, there I read that true neutralisation reactions, the example par excellence is the so-called neutralisation reaction, the proton plus hydroxyl ion gives a water molecule. But one calls all charge neutralisation reaction, that would also mean let's say barium plus sulphate gives barium sulphate which precipitates in water... all the action in which you compensate those charges are, as he showed, as he wrote, immeasurably fast.

You can easily calculate that if the reaction would appear at every collision, at every encounter between the two ions, then... and if the concentration of the ions were 1 molar, 1 mol/l, then the half-time of such a reaction should be only a fraction of a nanosecond, that means something like 10-10 seconds. And now the difficulty is, in order to measure the rate you have to bring together the two reactants, let's say the barium ion and the sulphate ion, by mixing two solutions, one containing the barium the other containing the sulphate. Or, in the case of neutralisation reaction, taking an acid solution which has an excess of protons and a base solution, basic solution, which has an excess of hydroxyl ions, and so that the proton and the hydroxyl ion can combine to a water molecule.
Now the difficulty is the mixing has to be complete, otherwise what you see is not the reaction, but is the mixing of the two substances, and that cannot easily be effected, not even in a sophisticated apparatus in less than a millisecond, less than a thousandth of a second. What happens is that you have to put these solutions under high pressure together and make a turbulent mixture of the two and then it flows down through an outlet, and that can't be effected in less than a millisecond. In fact, to get down to a millisecond was already a great success by Hartridge and Roughton in England. They developed a flow device in which they... before them the shortest times one could measure were in the range of seconds to minutes, and they managed with this device, flow device, to get down to a thousandth of a second, to a millisecond, and that was about the... and one thought, well, for a reaction to trigger you have to bring together the partners and that can't be effected in a time shorter, therefore he called it immeasurably fast reactions.

I went on with my thesis. But during my thesis, as I told you, I measured the specific heat in a closed vessel, that means the specific heat under the saturation pressure of that and the quantity you have to record and compare is either a specific heat at constant volume or a specific heat defined at constant pressure, Cp or Cv, so you have to calculate from that knowing the saturation pressure, you have to calculate it, and in order to do so you have to know the density of water very precisely and you have to know the compressibility of water.  And the compressibility can be measured most elegantly by measuring the sound velocity because the sound velocity is related to the square root of the compressibility of the water.
So Eucken at that time told me I should go to the Third Physical Institute because they were experts in sound measurement with ultrasonic waves. So I measured sound velocity in heavy water with ultrasonic waves and got all these data, but by that I got to know my colleagues there. There was Konrad Tamm and Günther Kurtze.  And so it happened that after I finished my thesis, and after Eucken had died, the physicist Richard Becker invited me to give a colloquium in the famous Monday afternoon physics colloquium. And at the same time he had invited Tamm and Kurtze also to give a lecture on their work and they worked at that time on the sound absorption of sea water.

The sound absorption in sea water is very high, very large, so the sound waves don't travel very far if you are at least in a certain frequency range, and that frequency was about 1 megacycle, 1 megahertz. And Tamm and Kurtze had found that there was a maximum of sound absorption, the two maximum - one in the megacycle range, megahertz, and one in the 100 megacycle range. These were very usual sonar frequencies. Now when compared, what means extremely high absorption by comparison? You look at pure water, at distilled water, it's hundred times lower, the sound absorption. So it's a real dramatic effect. Now what do people think? Sea water, that's much sodium chloride then, so they looked at salt water, and to their surprise the salt water has even less absorption than pure water. So what is it in sea water? Well, you know, sea water is not only salty, it's also bitter, and the bitter compound in sea water is magnesium sulphate. So it turned out that, very soon found out that if you take a magnesium sulphate solution it has also the high sound absorption, so there must be something wrong with the magnesium sulphate.

I had talked about my specific heat measurements also with ionic solutions, and I had talked also about magnesium sulphates there, and magnesium is a divalent ion, has two charges, sulphate has two charges, so it has very strong hydration, and therefore a quite big effect on the specific heat. So after I finished my talk, and after Tamm and Kurtze had finished their talk, the theoretical physicist Becker said, 'Well, isn't there a relation between the two talks? Eigen has talked about the hydration of magnesium and sulphate ions, and you find a high sound absorption, and you find two maxima. Couldn't it be that one maximum is due to the magnesium ion and the other maximum due to the sulphate ion?'
Now we must first see what does it mean, how does sound absorption come about. The first who did a theory on that was Albert Einstein in about 1916, 1917, he did a theory on sound absorption in gases. At that time, by the way, Nernst tried to measure it... the methods were not good enough to see the effect. Now here... what is the cause of the sound absorption is what we call a relaxation effect. It means that, to give you an example, you have... let's say you have a chemical equilibrium. Now a sound wave is a pressure wave, and the equilibrium is pressure dependent, so in the sound wave the equilibrium will always adjust to the corresponding pressure. That means it will oscillate also, but it can only follow it if the reactions are fast enough. In other words, if you have a megacycle sound wave the reaction must be complete in a microsecond, in a millionth of a second, in order to get to megacycle, which is 10-6 cycles per second, or if it is at 100 megacycles reaction, must be as fast as being complete in 10-8 seconds and so. And now the question is: if the reaction does not go fast enough, then it would lag behind the pressure wave. There will be a face shift between the shifting equilibrium and the pressure wave, and always in physics where you get face shift, you get absorption of energy, some energy is lost in that process, and that causes the sound absorption. So when it goes through a maximum, you know, at this frequency, if you take the reciprocal of this frequency, must be the relaxation time of a physical process which gets out of phase with the sound wave, and Becker thought maybe that the hydration, the water, interaction with the magnesium ion, gets out of phase in that range and the same happening with the sulphate.
I wasn't so impressed by that, so I immediately told Tamm and Kurtze, you can easily show this within one day. You know already that sodium chloride does not cause any sound absorption. So take sodium sulphate. There you have only the sulphate ion which could make the effect, and on the other hand take magnesium chloride, you know all of the chloride ion doesn't do anything, there you have only the magnesium ion. They immediately did the measurement and neither magnesium chloride nor sodium sulphate gave any sound absorption, so it couldn't be true that it was solvation or hydration of the two ions. It must be that both ions, magnesium plus sulphate, interact, and we soon had a complete theory for that. It is the penetration of the sulphate ion into the co-ordination shell of water molecules around the magnesium, and that goes in two steps. The outer shell goes fast, in 10-8 seconds, and the inner shell takes a microsecond, 10-6. At that moment, I remembered Eucken's words of the immeasurably fast reaction. I said, 'This is the method to measure chemical reactions, because this is microsecond'. Hartridge-Roughton only went down to a millisecond, a thousandth, this is a millionth of a second, or 10-8, is 10 nanoseconds, that's billionths of a second.
[Q] So the method was, just to start in the solution?
Yes.
[Q] I understand.
... to prevent the mixing. In equilibrium mix, the compounds are mixed, you disturb the equilibrium, in this case it was the pressure which disturbed the equilibrium, temperature wave is almost negligible because of the density maximum of water, so it's purely the pressure wave... So put in a pressure change, and watch it. And that can be done fast enough, so you prevent the mixing. And I say, this is the idea. I went to Bonhoeffer and said, 'When I come can I have a laboratory?' Instead of using sound pressure I use electric field density. Electric field you know propagates with light velocity so you can be even faster than with your sound waves. And so, that was the birth of the relaxation methods which brought me the Nobel Prize a few years later.

We had already worked out a theory, and this was in particular a theory on sound absorption. So that means the perturbing parameter was an oscillating parameter, it's a pressure wave. And it had to be... the theory followed an idea of Meixner, Joseph Meixner, you have to do similar thing as in a optical spectrum of coupled oscillators. You have to look for the normal modes, but this might be too difficult now to explain, and we worked out such a theory of normal modes, that means it involved some co-ordinate transformations to main axis and so on. So it was not a trivial theory.
[Q] It was a solid theoretical basis.
Yes, we had the theory and I asked Tamm and Kurtze to measure very clear chemical equilibrium which was well known, that of ammonia in solution, you know, NH3, the ammonia plus the water molecules, plus H2O, gives you an ammonium ion, NH4+, plus an OH- ion, this was a well known equilibrium... mean use a volume change and the pressure dependants, and I calculated the diffusion controlled reaction. Debye had worked on that and that's how I later became very well acquainted to Peter Debye. But we could calculate everything, and they did the measurement and within a few percent they found the data which I had calculated there. So it was a well established method and I said, but with sound it sometimes difficult to get a large time range because it's a resonance method, you have to use several frequencies. If you go to low frequencies you need very large volumes because the wavelengths of the sound becomes very large. That all is better with electrical waves and even we developed a temperature jump.
So I went to Bonhoeffer and told him, 'Look, I know the principle, know how to study fast reactions, and I will do so'. And we did this, within a year we had the first results, and in 1954 it happened that the Faraday Society had a meeting with the title The Study of Fast Reactions.
[Q] Where?
That was in Birmingham. So I was for my first time was invited to England, was first invited to Cambridge to meet later friends, Ronald Norrish and George Porter, we got a Nobel Prize together in 1967 then, and we went together from Cambridge to Birmingham. And there it happened that I talked about my methods. One of the first speakers was Ronnie Bell. Ronnie Bell has written a famous book on the proton in chemistry... and Ronnie called his reactions 'fast reactions'. So the next speaker was Roughton. Roughton said, 'Since my predecessor has called his reactions fast...' he went down to milliseconds as I told you, 'I must call my reactions "very fast" reactions'. And then came Ronald Norrish with a flash photolysis which went down to the microsecond, and said, 'So I'll have to talk about "extremely fast" reactions'.
Then I had to give my lecture and say, 'I'm sorry, my English is not good enough. The reactions which Professor Norrish talked about, he called extremely fast, but these are the slowest among my data. I have to go down to 10-9 seconds, how should I call them?' 'Oh', they said, 'call them damned fast reactions or goddamn fast reactions'. So that was the origin of it. And that was a little bit sensational at the meeting, that suddenly one could get down to that word, and the year afterwards we measured the rate of the neutralisation reaction, proton plus hydroxyl ion with water, which turned out to be the fastest reactions in solution.

I didn't solve the problem, the mixing problem. I circumvented it, and this proved to be a very useful method. I can perhaps explain it still a little more directly with the reaction we started two years later, when Leo De Maeyer came from Belgium and entered our group. I think he came in 1954. By that time we tried to study the most prominent reaction many people had tried before, namely the neutralisation reaction - proton plus hydroxyl ion to a water molecule. Now to go into equilibrium means into an equilibrium where the two partners, proton and hydroxyl ion, are present at equal concentration. That means we had to produce very, very pure water, as Kohlrausch did in the '90s of the last century. So we had to distil for a week, we had to heat the surface of the apparatus, of the distillation apparatus, so that no impurities could come over, and we reached a conductivity which indicated that we had 10-7 molar protons and hydroxyl ions versus 55 moles of water molecules. And we decided to disturb this equilibrium by an electric wave... an electric wave with a very large electric field strength, something like 100,000 volt per centimetre. Now, such an electric wave can travel with almost vacuum light velocity, less than that, which means it travels over 1 centimetre within 10-10 seconds, that's ten billionths of a second. So with that we could see indeed a shift of the equilibrium and we could measure the relaxation time by which this equilibrium was achieved... a new equilibrium.
You know, in ionic reactions that was found already by Maxwell, long ago, and was theoretically fully explained by Lars Onsager.  An electric field shifts any ionic equilibrium by pulling the ions apart, so to speak. Now we used that and we could measure the reaction rate... such a recombination reaction which in proton and hydroxyl ion of course has a relaxation time which is dependent on the concentration, and since the concentration of these partners is very low, as I say 10-7 molar, the time was in the microsecond region and we could easily follow that. The rate constant we derived from that turned out to be the rate constant, the fastest ever measured rate constant in solution. Later on it turned out it's the combination of a proton with the hydroxyl ion is even faster than the combination of a proton with an electron. One could think that the electron would be more mobile, but that's not true. It's probably more localised and, to give you a feeling of it, if you would have one normal... one molar acid solution, and could mix it fast enough with the one molar base solution, the reaction would be over in about 10-11 seconds. That means a hundredth of a billionth of a second. That's real damned fast indeed.
[Q] Yes, but you can also call it diffusion controlled, instead of damned fast indeed.
Yes, it's diffusion controlled, that's true, where one should note that diffusion of proton and hydroxyl ion is faster than of any other ion because it can jump through hydrogen bonds and have a special anomalous mechanism.

I still was... after finishing my PhD... this is the sound absorption appeared at that time, about 1952... still was in the University Institute of Physical Chemistry, which formerly was the house of Nernst. He lived there.
[Q] The private house? 
Yes, private house. As I said, Eucken had died, and his former assistant, Wicke, Ewald Wicke, was in charge of the institute until a new director was called. We agreed that we all stay there in order to keep the teaching alive until a new successor was elected, which appeared in 1953, it was Professor Jost, Wilhelm Jost. I think Wicke then got a call to Hamburg and I went to Bonhoeffer.

[Q] Can you just mention some of the names, let's say Europe - from Denmark to south, Italy, or from the United States, just to get the feeling? 
Yes, well one of the great inorganic chemists in Europe was Gerold Schwarzenbach in Zurich, Lars Gunnar Selèn [sic] in Stockholm, who in fact had invited me already in 1953 to present a lecture there at a meeting, and Jannik Bjerrum in Copenhagen. A famous inorganic chemist, of course, one who later received a Nobel Prize was Henry Taube, at that time he still was in Chicago, now he's in Stanford, and Jack Halpern and many others.
[Q] I understand your place became a mecca for measuring mechanisms of inorganic chemistry with ligands and later on also with organic compounds. 
Yes, let me try to explain it a little more. I said before that a metal ion surrounds itself with two shells of water molecules, and if it combines with a ligand, that ligand has to penetrate through this water shell.  And the chemists had, following nomenclature by Ingolt, had called it substitution of first order or second order as a rate limiting step. First order he would mean that before a ligand can enter the shell, a water molecule leaves, it's a first order reaction, then the ligand can move in. And the second order means that the ligand first comes in and replaces a water molecule from the shell. We could clarify many such reactions, and we really got a periodic table of reaction rates, all rates between, well, for the main group elements, for the alkali, the alkaline earth, the earth metals, for the transition elements, and we really could correlate this with electronic structure and so this clarified a whole field.

I had also worked on electrolytes... on electrolyte theory. And I remember my first visit to the United States was also in 1954 when I came to a birthday party of Peter Debye which was arranged at Yale University by Lars Onsager and his colleagues. And...
[Q] What birthday of Peter Debye?
Peter Debye was 70 years old that time. And he took me away and said, 'Give up the work on electrolyte theory, the first approximation has been done...',  namely by himself and Hückel, and he said, 'Don't try higher approximations, go on with your fast reaction work, that's really something new'. And so we became very good friends. Later he invited me to Cornell University, I became a Professor at Large at Cornell University, I gave lecture series there, so this opened a very nice contact. Also with Lars Onsager, as you know yourself we often visited him and worked together.
So I should say perhaps a word about you. It was again a conference on coordination chemistry, the so-called ICCC, International Conference on Coordination Chemistry, at Vienna in 1964, and I think you worked with Professor Gutmann there, so you were in the meeting office and I came a little late...
[Q] As always...
... and so I was nicely welcomed by you. And that's also when I asked you why don't you come to Göttingen to do a thesis with me, and you came to Göttingen, and again we thought at that time already a little bit about biological reactions, we thought of measuring complexes between ATP, adenosine triphosphate, one of the most important energy sources in living cells, and magnesium and calcium because those reactions usually require either magnesium or calcium ion to proceed. But at the same time Max Delbrück visited us, remember, and he brought along a molecule and say, 'Why are you studying those boring molecules, I have something which is much more interesting', and that was one these cage molecules. I think it was monactin and dinactin.
[Q] Monactin.
I am mentioning these because this is a molecule which completely surrounds the ion, so in order for the molecule to react with the sodium or potassium it can specifically distinguish between two chemically very similar ions, the potassium and the sodium ions, but it can distinguish by orders of magnitude. And in order to do so it has to completely wrap around the ion, in other words substitute all the water molecules from the inner shell, which if you look for the hydration, heat, this is some 100 kilo calorie.  And so one starts to wonder how could that be a fast reaction? And apparently it does it again. It brings in one ligand, substitutes water molecule, brings in the next ligand, and it does the whole thing within 10-8 to 10-9 seconds. So this is really one of the... again of the very rapid coordination reactions there. Now you studied then other substances like, I think from mushroom, from Amanita?
[Q] But they were all of the kind of these, sorting 'caging' the molecule to be selected.
Yes, and that's a trick to completely engulf the ion so that all water molecules are substituted and then the difference in the solvation energy, in the hydration energy, between sodium and potassium, sodium is a smaller ion, can be become effective and that's a very important reaction. Now a nerve membrane you need a rapid exchange of sodium and potassium and those substances called membrane carriers are involved.

Now in the '50s, as I said, many visitors came, many postdocs came, they all wanted to learn, to study fast reactions.  And when they left they took either T-jump method with them or one of my secretaries... married a secretary, and so we had a very high turnover of secretaries and we built many such T-jump machines for other laboratories in our machine shop.
[Q] But there was no commercial...
There was no commercial... Leo De Maeyer tried later to do something like that. So this was the '50s.  In the '50s, in 1957, unfortunately Bonhoeffer died. But at that time I was already made a scientific member of the institute and that is a tenure position corresponding to professorship at a university. In '62 I got an independent Abteilung, a division, of which we called first Chemical Kinetics, later we called it Biochemical Kinetics, and in 1964 I became Director of the  Institute.

In the midst of the '60s I also became President of the European Molecular Biology Organisation, so-called EMBO. My predecessor was Max Perutz, and my successor then was Nils Jerne.
[Q] But I understand EMBO at that time was still an organisation without any building, it was just...
Right, without any laboratory.  And what we tried at that time is to found a European laboratory of biology. I remember people most active in that was Jacques Monod, for instance, François Jacob, Sydney Brenner, Max Perutz, John Kendrew... John Kendrew was Secretary General of EMBO.
At that time we met very often at Geneva, at CERN. They...
[Q] ... offered the space.
Offered the space, and I remember Jeffries Wyman came, Arne Engström from Stockholm.
[Q] So there were representatives of every country? 
Yes. Once Jacques Monod invited us all to Nizza... Nice... because he could get a very nice plot for the institute and I really was in favour of getting the institute to the coast of the Mediterranean, but politicians didn't come along with that. I don't know, there was... I think they just had founded Grenoble in France and I think in England in Harwell there was the fusion project in physics, so the next European laboratory had to come to Germany, and it turned out that Heidelberg offered the best place to it. And during these years we really brought about the so-called EMBL, that means European Molecular Biology Laboratory, and its first director was John Kendrew.

We also tried to found in the Max Planck Society an Institute of Music. So again, I have said before that I did much music as a child. The first year during my study I didn't have a piano, but later on I could manage to get, first, access to a piano and, finally, to buy one myself...
[Q]  Second-hand?
Yes, and started again to take lessons and went to a brother of Paul Hindemith, Rudolph Hindemith at Munich and his wife Maria Landers, who was a professor of piano classes at the music academy in Munich. There I stayed with them for ten days or so and practised eight hours a day. So I really took up my piano work again, which later on when I become more closely known and related to Paul Sacher, who heads the Basel Kammerorchester, Chamber Orchestra, we played several times piano concertos, mostly from Mozart and we also took the CD later on with David Epstein in Boston with a very good orchestra, partly... Boston Symphony Orchestra... members of the Boston Symphony Orchestra. So that appeared at the same time.
Now what about the Max Planck Institute for Music? We had one of our big annual meetings of the Max Planck Society.
[Q] May I just interrupt? You are always talking about 'we'. Would you please let us... who is we? There must be many musicians but...
I will immediately tell you. We had... we is the Max Planck Society had one of its annual meetings and that's usually in the morning, there is some orchestra playing some music and I found the music lousy, and said this later on at dinner. They said, 'Why is that?' So I say, 'Well, they don't have Max Planck Institutes'. Then one of the elder statesmen in Germany, an industrial... Wurster, say, 'That's a good idea, I get you some money, and you bring together a committee for having a Max Planck Institute of Music'. The idea was to have something like the Bauhaus, which came about in the '20s in art and in painting and architecture. We thought that such an institute could have four divisions; one with practising musicians with chamber music, another one with...
[Q] Creating music...
Creative music... composition.  That's a good word - creative music. A third one on technology of music; that means new development of sound, new development of instruments and computer music, and finally music history. And we had a good committee with famous musicians, Rudolph Serkin was among them, Dietrich Fischer-Dieskau was... Edith Picht-Axenfeld, Georg Picht. The scientists among was Werner Heisenberg, Carl Friedrich von Weizsäcker, and our chairman was Paul Sacher. That is the origin of our friendship with Paul Sacher.
So we tried, we came up with the proposal for the institute, but the proposal didn't get through in the Max Planck Society. I forgot the main person in that... that was Pierre Boulez and Pierre Boulez was supposed to become the Director of the Institute. Now, Pierre got the money from Pompidou and founded it finally in Paris.
[Q] Yes but this was...
... the Centre Pompidou... later. But he could manage and I think he really used part of the plans we had worked out during that time. There were many trips down to Heidelberg, to Basel, we met in Paul Sacher's house.
And so at the same time I meanwhile had founded a family also in the '50s already, had married Frieda Müller, had two children, Gerhard, a son, who is now professor of elementary particle physics in Bergen in Norway, a daughter who is an interpreter in English and French.

Having the new method, the fast reaction... we soon could show that you don't measure only the reaction rate. Some overall rate, but you can measure a whole spectrum of time constants as you do spectra and resonance spectra in optical spectroscopy. Here you measure spectra of relaxation times which means if a reaction mechanism proceeds in many steps you get the whole mechanism from it and that's even more important than just to know how fast the reaction can go. And one of the obvious objects of study of course were enzyme reactions, because an enzyme is a complicated molecule, a protein molecule. An enzyme has to bind the substrate which it will turn over during that... it might change its conformation, it might... the reaction might go in several steps, it might form intermediates, and finally the product have to dissociate in order to allow the enzyme to re-enter the reaction cycle. So an enzyme reaction, by definition, is a complex reaction network. And we applied our relaxation technique to this, and with much success.

Jacques Monod and François Jacob had the idea of allosteric reaction control by enzymes, which meant you can switch on and off the reactivity of an enzyme molecule by binding another ligand. The ligand might be the substrate itself, which in addition bind... it might be the product of the reaction or it might be some other effector. A typical allosteric protein, not an enzyme but you might say enzyme...
[Q] Honoris causa?
... honoris causa is the haemoglobin molecule, that molecule which binds the oxygen and transports it to the places in the organism where it has to be burnt... where the food has to be burnt. So in other words the molecule in the lung, where oxygen comes in, must take up as much as possible oxygen, so it must have a high binding capacity while, when it comes to the cell places where the oxygen has to be given off, it has to have a low affinity to oxygen in order to give it. So you see that is a typical protein in which the control of the reaction plays some role.
Now we, when I say we again it was Kaspar Kirschner, who came from Feodor Lynen, from Munich, to me, is a biochemist, he choose another enzyme, glyceraldehyde phosphate dehydrogenase, and it turned out that this enzyme behaved exactly according to a mechanism which was proposed by Jacques Monod together with Jean-Pierre Changeux and Jeffries Wyman. In 1965, '66 there were several papers on this exciting new field of allosteric enzymes. There was this paper by Monod, Changeux and Wyman, there was another paper by Koshland, and there was our experimental study.

The mechanism which Monod proposed is that.. well, Monod really is a Platonist, it's a symmetry mechanism. It said, if one sub-unit changes its confirmation to the other, then all the other sub-units have to come along to make it symmetric. So then you see already that a Monod mechanism consists of at least three steps. One step is conformation one... which is, let's say has a high affinity to its ligand... so there are four sub-units, so four ligands of four substrates might bind to the enzyme, so you have a series of binding steps, coupled binding steps. Then you have the other confirmation of different, lower affinity, again four steps of binding, but the enzyme can be either in that state with all its sub-units or in the other states. So you have a co-operative transformation between the high affinity and low affinity state. So you must find at least three types of rate constant, binding in the high affinity, binding in the low affinity, confirmation change among them, and that's exactly what we found. Kaspar Kirschner did this study. There is one reaction in the range of microseconds, then there's another reaction in the range of 10 to 100 microseconds, and there's a third one in the millisecond range and one showed the concentration dependence of binding high affinity, the other low affinity, and the confirmation changes of first order reaction. So this was a big success and Monod came here and he was happy.
[Q] So I understand that to measure this reaction was only possible in your laboratory with a relaxation method.
That's right.
[Q] I remember, I think it was a T-jump. 
It was done with a T-jump. And this T-jump method works down to a microsecond and that was indeed the shortest time in that reaction.
Well, and then there was Koshland. Koshland proposed the different mechanism, which I might explain also. He had the idea of induced fit, which means... there is no symmetry among them.  If the first ligand binds, it induces a fit, and then increases the affinity of the next sub-unit, and if the second binds it still increases it for the next so that you have the successive binding with increasing affinity. Well it turned out that this first mechanism did not comply with the Koshland idea, but later on we found many other systems which followed the Koshland rather than the Monod mechanism.  And we came up at that time with the very general mechanism in which you can combine both, and at that time also the biochemists really realised that this method really could give them new insights also into the reaction of the living part.

I should perhaps explain what T-jump means. 'T' is for temperature, and temperature jump means we jump the temperature within a microsecond by 10 degrees centigrade, or anything you like. We do so by rapidly heating electrically the solution, and then we look with some optical method, either light absorption, or fluorescence, or polarimetry... so using polarised light.
[Q] That means that you have added a dye molecule, indicator, just to... 
Well, if you study things like haemoglobin you have already a nice dye in there, but the same is true for many of the enzymes when you add certain material. So there is no difficulty at all and we will certainly later talk about those reactions when we go on.
[Q] And the T-jump were also those machines which were built and people could take along home to their own laboratories?
Yes.
[Q] The other more sophisticated machines just were available in the Bunsenstraße.
Yes.
[Q] Bunsenstraße was the old institute.
But by then we had about ten machines standing there, and we had many people in our laboratory who came for a longer or shorter visits, did some measurements with us and... that was the time of the '60s. You see, we went through several periods, and there were several waves of visitors. First the inorganic chemists, then of course with all the reactions of proteins, you have acid base catalysis, so we came into organic chemistry and then finally, once you are in organic chemistry you are not far from biochemistry, and as I said before the enzymes and the more complicated reaction networks were the best objects for such studies of what we call relaxation spectrometry.

Now we come to the question of life, and...
[Q] When did you start to think about 'life'? 
Yes, one of the main results of these studies was that we found that enzymes are optimal catalysts. What does optimal mean? Optimal does not necessarily mean that they are the fastest possible, because an enzyme has not only to take care of a fast turnover - it has to be specific. So in fact in an enzymatic reaction you have two contradicting processes, namely you want to do the reaction as fast as possible. But, on the other hand, the reaction should be specific. The enzyme should accept only it's very specific substrate, and a substance which is similar to it should not be accepted, because otherwise the life process would get mixed up. So, to be specific means it has to make a strong bond, and a strong bond means a slow reaction. If something is very fixed, then it takes a longer time to break it apart. So you see the two contradicting things. First of all the enzyme and the substrate have to combine. They usually do that diffusion-controlled, so that's a very rapid process. We found many enzymes where that speed is given by the diffusion-controlled reaction. Wonderful if this could also be the total speed. But now comes this binding... must be very strong, so that something which is similar can dissociate before the reaction takes place. So in order to get it specific, you need a sufficiently strong binding, and then you need the turnover from the substrate into the reaction product, which I said could appear in several steps involving the enzyme changing its conformation, has to bring all the reacting groups in an optimal contact to this.
So, what are the requirements, then? Well, they should combine rapidly, that's diffusion-controlled. Now before they can come apart, there should be the turnover. On the other hand, the reaction... the substrate coming apart, doesn't have to be much slower than the turnover, because otherwise when this is very slow the product wouldn't come apart again. And when we look at an enzyme reaction, and we have studied many of them, they always were an optimal combination of these various requirements. So we ask the question: how come? How did nature manage? The biologists among us said, 'This is Darwinian explanation, survival of the fittest.' We said, 'Wait, wait, Darwin developed his principle for living organisms.  These are molecules. How do the molecules know?' So we had the feeling we should understand more about life at the molecular level.

The complete theory showed that this error threshold is a phase transition type of problem. Physicists work with such phase models, for instance in ferromagnetism they talk about the Ising model, and it turns out, yes, our theory of self-organisation in micro-molecules in nucleic acids makes use of this, and so we could develop an exact theory. The result of the theory is that what biologists call the 'wild type' is not really one type, it's a whole spectrum of mutants... still stable with respect to the error threshold, but a far distributed mutant spectrum which we called quasispecies. And then we found out that due to the error threshold there must have been some difficulty in the beginning to get together enough information for an organism, for a whole biochemical apparatus of reproduction, and that was the origin of the hypercycle work.

Why do you need reproduction, you can ask. Well, because of complexity of those molecules. Look, the smallest living unit on a molecular level is a gene. A gene encodes a protein molecule, and the protein is the smallest living... the smallest molecular entity in a living organism. Now the smaller protein molecules we deal with are made up of, say, a hundred amino acids, and you know an amino acid... there are twenty classes of amino acids... and each amino acid is encoded by a triplet of nucleic acid building blocks, the A, U, G and C we talked before. So that means the smallest genes are several hundred of these monomers of the four-letter alphabet - AUGC or ATGC. The T and the U are very similar molecules, one is used as a ribonucleic acid, the other is used in the dioxyribonucleic nucleic acid. But most genes, in fact, are about a thousand such monomers, and now you see what I mean by complexity.
Take in the first position of the gene, you can have either an A, a T, a G, or a C, so there are 4 possibilities. Now comes the second position, you can have again 4, so in a dimer you have 4 by 4, 4 x 4 possibilities. In a trimer 4 x 4 x 4, and for each position you multiply that by 4. So that means if you have 300 positions, you have 4300, or if you have a thousand positions you have 41000. What does it mean? In the decimal system the logarithm of 4 is .6, so 41000 is 10600, a 1 with 600 zeros. And one of these molecules is the one you are dealing with, and you must conserve this information. So you see, you have so many alternatives that... and information which once appears never would come again, unless you reproduce. That's the need, the necessity, for reproduction.
I can perhaps give you some example. The physicists now can calculate how much matter we have in the universe. They don't know it exactly because they don't know the dark matter yet and they don't know whether the neutrino has a finite mass, but it's in the neighbourhood of 1080-82, 1082, so the '1' with 80-odd zeros, that's a number which is absolutely small, negligible as compared to the numbers I gave you before, 10600. So what can you say?
[Q]  But you forgot to mention the unit 1080, in what unit? 
Oh yes, yes, good for you. The smallest mass of a particle, a proton mass... 1080 masses of protons, not more.  Then you can just as well calculate the volume of the universe and say let's assume the volume of the universe made up of little cells and let's make each cell of the size of a proton.  That means it has a dimension of 10-8 cm, that's 1 angstrom unit, in a cubic array, so let's use as a unit the cubic angstrom, that means 10-8 cm in each direction. The total universe, or a sphere with a radius of 10 billion light years, has a volume of 10107 such cubic  angstroms... only 10107. So you see the universe is by far too small, and its existence time to the big bang, these are 1017 seconds.  It doesn't live long enough to test out all possible molecules which we have in our genes. So absolutely this is complexity, combinatorial complexity. If you don't reproduce that you lose it forever.

There are these molecules which are the adapters of the genetic code. That means each codon, that means a triplet of these nucleic acid building blocks, is associated with an amino acid. And the question is: when did this code originate? Now we know that the recognition between the codon and the amino acid has to be mediated by an adapter which we call tRNA. And nowadays there are many sequences of tRNA known, so that we can do two types of studies. We can look at a given tRNA, and look at the same molecule in different organisms, and then construct from those sequence similarities, among these can reconstruct a phylogenetic tree. And the other one is we can take a given organism and take all its tRNAs, they must have occurred when the genetic code came about, and look at these families of all the tRNAs for all the different organisms.

Life came about whenever the conditions were...
[Q] Suitable...
...suitable. Our planet, the earth, is assumed to be 4.7 billion years old, so it took several hundred million years for it to cool down, to develop a chemistry in which these reactions could come about, so life couldn't be much older than 4 billion years. And we say, 'Well, when the conditions were all right, life was here'. And then it took another 3 billion year before a single cell started to differentiate and before multicellular organisms came about. So life as such came very quickly, while the evolution then took its time. So this is one of the big requirements, we started asking the question: what is necessary in order for life to come? We said reproduction. Without reproduction, no evolution, no selection, no evolution. Reproduction requires a particular kind of molecule, namely the nucleic acid. It requires that one building block binds preferably to another one which we call complementary.  In the nucleic acid it's the A with the U or the A with the T, and the G with the C. So whenever you have a sequence of these letters you produce by copying a complementary one, like in photography you produce a negative of your... and the negative can then be converted into the positive...

With Darwinian selection, the one which is based on replication, you need that certain substances disappear completely, not being present in a certain ratio. In the law of mass action you can only have ratios of substances, no substance can be at zero concentration because that would violate... there's always a free energy difference at equilibrium. But here with selection you can... selection means some concentrations get zero and others get selected.  And so there is a need for the system to be far away from chemical equilibrium. And that's... that you have to put in energy, and energy is metabolism, in other words you put in the free energy of certain reactions in order to keep the system from fading away into equilibrium.

These three prerequisites: the reproduction, replication... the replicative reproduction, the mutation, and the metabolism are the prerequisites of molecular self-organisation into living systems. There come other prerequisites of a more specific nature when enzymes develop the longer, as I say, it's as long as the machines... so long as the information bands become the more precise, you have to do the reproduction... more complicated the enzyme machinery becomes. This was the recognition in the '71 paper.
[Q] And it somehow was triggered also by the basic idea of Karl-Friedrich Bonhoeffer who wanted you to get into biology much, much earlier...
Yes.
[Q] But this... 
It was a different type of reactions he was interested in, as I said mainly connected with nerve conduction, the conduction of nerve pulses, but this is the basis of life. Now, then I mentioned what comes out from these properties is what I call the quasispecies. In other words it's a distribution of mutants which is stable, doesn't lose its average information content and develops up to optimal reproduction.

In nature there's not only reproduction what we find, we have to build enzymes, and the enzymes have to be optimal catalysts. And the catalysis is not a reproduction reaction, you have all sorts of reactions, so you needed then a class of molecule which you can adapt to any reaction you need in your complicate system. And now comes the difficulty. What you have to keep is the information. And for that you have your reproduction below the error threshold. But what you want to test for is functional efficiency, and that you can only test with a given enzyme. So what you have to keep is the nucleic acid's information strength, but what you evaluate is the protein molecule, which is translated from the nucleic acid molecule. So I call that the genotype/phenotype dichotomy. In other words the phenotype, which is to be evaluated and found to be good or not good... not well adapted, has to tell its genotype, 'I'm a good one, keep my information and destroy the others'.
And that means you need an additional feedback loop. Before, we need one loop, replication, the plus strength makes a minus strength, the minus makes... this is a cycle really, reproduction cycle, yes, as you have it in quasispecies. Now you can also translate your information and the translation product has to feed back, has to tell 'I'm a good one', or 'I'm a bad one'. And that we called hypercycle.
[Q] So the hypercycle is, so to speak, a theoretical basis of life...
Yes.
[Q] On a very low, low, low level.
It serves two purposes. First of all it allows you to make... build up a network of genes, because the genes can't become longer than allowed by the error threshold, and here you can put together several through this loop, and secondly it allows you to overcome the genotype/phenotype dichotomy. And this was first a purely theoretical concept, but later on we found it experimentally.
[Q] Can you tell, what was the crucial experiment to verify this?
Well, I will tell that in more detail, but it was the infection of a cell by a virus particle... shows exactly this process and it's exactly of hypercyclic nature.

One could say you can't do any experiment which exceeds the lifetime of a PhD student. But that was our surprise... if you choose the right conditions you can do it. You can do it even in days or weeks... days and hours, depending on what you are... you are never trying to evolve any living creature. What you try is you ask very special questions, which are key points in evolution, and those experiments can be easily done.
[Q] Who was the first to do evolution experiments?
Yes.. now, we were... came in... it was my friend Sol Spiegelman who really was a pioneer in doing the first experiments... cell-free evolution.
[Q] But he made it more on a qualitative level, I understood. 
That's not... I wouldn't call it qualitative. He did already quantitative measurements, but at that time there was no theory yet and he didn't choose the best possible conditions because he couldn't know about certain... For instance, he used an enzyme which he isolated from a bacterial virus, Q-beta virus, and that enzyme is able in a cell-free solution to replicate nucleic acid so he can do wonderful experiments on replication of nucleic acids. But he didn't know about error threshold. So he did not use a whole phage Q-beta and many of these quantitative experiments that he rather used relatively short nucleic acid strengths, let's say 200 base... they have 200 bases. The true virus, Q-beta, has 4600 or over 4000 such pairs and its error rate, its mutation rate, is adapted to this length, in other words it is just at the error threshold for this long strand. Now using only these short strands of 200 bases means that he is much too precise, so evolution is slow, he makes too few errors. And therefore what he could show were principle things, but quantitatively one could do much better.
[Q] But nevertheless he is the pioneer of evolution experiments.
Yes. One of the problems in evolution is, as you know, the natural process went on over many, many years, so you want to have a indefinite...
[Q] Perpetual...?
... perpetuation of evolution, but since the substances grow you will soon have populated everything.

Weissmann was the first experimenter who recognised the importance of the error rate. And he decided to measure it with Q-beta. And a funny story was, we had our winter seminar... we will later certainly talk still about our winter seminar, but I might take this ahead of time.  He came to one of our winter seminars and said, 'Manfred, I have an experimental result which must interest you'. In fact he had two experimental results. The first one, he said is, 'I measured the error rate'.
[Q] What system did he choose? 
Q-beta... phage Q-beta. With a total phage and with an infection. Here was not Spiegelman's experiment, but he infected coli cultures, and he said, 'Well, it has a very high error rate, about a million times higher than, let's say, a coli cell'.
[Q] Quite a sophisticated system. Coli is quite sophisticated.
Yes, it's a living organism and there's viruses dependent on a host cell of course. But, that's funny, it's a million times larger. So in viruses we should expect much higher error rates than in other organisms. And the second result he brought out was that he said, 'This system doesn't consist of a given sequence. It is a distribution of sequences'. How could he find out about it? He had a population of virus particles and then he took out a small volume element where only one virus particle is in, and cloned it, and grew up a population of each single virus particle. And then he measured the sequence of it and he found, in the different clones, they are all different sequences.  No sequence agreed with the other, there were a few errors but no one... So I said, 'There is no wild type. The wild type is an average of all these sequences'. And I came to this seminar and said, 'Charlie, listen to my lecture. I have a theory which first tells you that viruses must have an error rate which is a million times larger than coli', which meant... it's not quite a million times, about a million, but it's more than a million times compared to human cells for instance. So the error rate which Weissmann had found was, I think, 3 x 10-4. That means about every three thousandth building block is wrongly copied. And since the Q-beta has about four thousand odd, it means in each replication round you make at least one mistake. And these mistakes are necessary for evolution, for adapting it. That's the first result. My theory told me the error threshold is exactly of that order of magnitude, namely that the product of the length of the virus times the error rate is of the order of magnitude of one. So you have to make mistakes in order to adapt to new... but you must not make too many mistakes then you lose your information. Was exactly... we calculated from my equation, and got exactly his number was... what he found experimentally.
The second result, that he has a mutant distribution in which no sequence agrees with any other...
[Q] 100%.  Does not agree by 100%. 
 Not by 100%, of course, the average sequence must be the same otherwise you lose the information. But, I say, that's exactly our quasispecies model.  The quasispecies tells yes, if you are at the error threshold, your reproduction is so that you never make a completely exact copy.

Think of the AIDS virus. If the AIDS virus enters a person... a host, it's just one single virus particle, so before you can measure it in your five... six litres of blood you have in your body, that virus must multiply, multiply, multiply. A biblical verdict, multiply. And you can just detect the virus when it is about a billion particles in your blood. A billion particles is still an exceedingly low concentration. You know...
[Q] 10 to the what...?
... in a gram of water you have about 1024 molecules, that's the Avogadro number, so 109 is a very small number if you take your total blood content of the body. But what does it mean, a billion molecules? There is first only one molecule, and the next moment it duplicates, there are two, and the third moment you have two times two, that means four, then you have eight, you have sixteen, you have thirty-two, sixty-four, and before you get a billion you have to go through thirty such replication rounds, because 230 is just about 109. Which means that all the particles have on average accumulated thirty mistakes, thirty errors, because they have gone through thirty such replication rounds and in each round there is on average one. Of course what you truly have is a Poissonian distribution, which means if you are at your error threshold a third of your molecules has no error, a third has one error and another third has more than one error. That's about what you get at the threshold.
So he had the experimental proof for our quasispecies model. And that convinced us also that we have to do experiments in biology.  You cannot just make theory, you have to find out is your theory... do you really find the effect which plays a role in nature.  And this turns out to be a general law in nature.  Evolution takes place just below the error threshold.

I made a kinetic theory of replication, which applies to molecules and not to organisms... to individuals, as in the case of Darwin. And I found if molecules reproduce like nucleic acids do, and if they make mistake, I have a kinetic equation which says the temporal dependence of that concentration involves a term which says inherent autocatalysis or its proportionl to its consonant... it has a term which says mutation, it makes with a certain probability any possible mutation according to the number of errors. I had a whole set of equations with the matrix and there was a mathematical way to solve these set of equations, and out came the quasispecies. In other words it shows it's not true, but one always thought about Darwinian evolution, it's not the wild type, a single type, which gets to selection, it's the quasispecies that is a... well, mathematically it's a principle access transformation. You have a matrix, you diagonalize your matrix, and you find that what is selected is not the single molecular species but rather a clan of species, and due to their couplings among... making themselves via mutations... you select this whole clan, and it is not the single species which has to be best.  The clan as a community has to be the best reproductive behaviour, then it comes out.
So the quasispecies... I didn't make a theory of quasispecies... the quasispecies was a result of this kinetic theory of replication.
[Q] So the advantage is for selection, not the individual, but a clan with... surrounded by many low error mutants, and the advantage of it is, if the boundary conditions change, that it is much more dynamic and flexible to adjust to new conditions.
Yes. Now you see already the difference to simple Darwinian type of behaviour. You produce a quasispecies, a large distribution of mutants, And everything is tested in that, and the settles... the population settles in a range where you have the best clan of species, with an average sequence in the middle. Now if you want to get selection by... if you change your environment, and adapt it to a new environment, you don't take anything inside the quasispecies, you have to take something you have not yet tested, and that's at the periphery. So the next one which gets selected is something which appears de novo at the periphery of the equation and therefore it's certainly a punctuated type of evolution.

What parameters do we put into our theory? Again, we said, 'Well, we have to measure these parameters. We have to do experiments and find out how nucleic acids reproduce... what the enzymic mechanism is'. We just have talked about fast reaction work, in which we showed that enzymes are complicated reaction systems with many reaction steps, so here we started now to study in detail the replication mechanism of nucleic acids. The first experiments were very simple experiments... were relaxation experiments on how nucleic acids behave.
[Q] You already started in the late '60s?
Yes, I mentioned already the fast reading rate, and that was mainly Dietmar Pörschke who did first a thesis on it and then continued and studied... or actually also looked at more complicated reaction system like the repression systems, lac operon, the famous system of Jacob and Monod. So first we started to know more about properties of nucleic acids, but then we had to start the replication mechanism, to use Spiegelman's enzyme... isolated enzyme, and look exactly at the kinetics of replication. And that was Christof Biebricher who did this work, and we have years of work there where we completely measured the mechanism of nucleic acid replication so that we could put in the right parameters into our equation and not speculate about any models.

Quasispecies is a large distribution of mutants in which you have those which are very efficient, and they keep the quasispecies alive, and you have mutants which are produced by the efficient ones but themselves are very inefficient. I will show you later an example of that. So you have a big distribution of many mutants of low efficiency and a few...
[Q] Very few.
... being high efficiency, some neutrals among them as Kimura had proposed... neutrals... they really find them there. And when I talked about this quasispecies more in our winter seminar, our friend Shneior Lifson... Shneior Lifson is an Israeli scientist and older colleague of mine, a wonderful friend and has always very good stories... so I saw his eyes were... 'Shneior, what's the matter?' He said, 'Oh, now I understand why man is called Homo sapiens, although most people are stupid'. So that was a nice story in the winter seminar.

Let me tell you a little bit about a true evolution experiment and you will ask why do you do... why do you make experiments when you know the mechanisms... all well...? You cannot calculate what is the product of evolution. It's so complicate, and I will tell you a story of an experiment we did here.  It was done by a student... the experimental work was done by a student in his PhD thesis, Günther Strunk. It had to use a machine because the replication time in this... we optimised our conditions so that the total replication of an RNA strength took less than a minute. So everything had to go with the machine controlled and we used Spiegelman's technique of serial transfer.
[Q] But maybe you should... who built the machine? I remember these were doctoral theses, diploma work, so they must have...
Oh yes, it was an electrical engineer who did a doctor thesis in electrical engineering here, Hajo Otten, and then other people worked together with him. Günter Bauer worked on that machine, and finally Günter Strunk and Rolf Günther... ja, he did the latest...
[Q] ... more sophisticated...
... more sophisticated parallel machines. Now let me explain this machine. The reaction vessel is a little silver plate, it has a little deepening which takes up a few microlitre of substance. Now, first surprise, our enzyme didn't like silver, like certain ladies prefer gold over silver - so did our enzyme. We had to make a gold inlet in order to persuade the enzyme to work, but that it did beautifully in the gold vessel. Why did we take silver plate? Well I said you let it grow then you stop the reaction, take a tenth out of it, let it grow, stop the reaction. And we start and stop the reaction by a temperature jump. We simply put the silver plate, if it is not growing at 0°C, and when it is supposed to grow it is pushed on to a metal block which is 37°C or above 30°C... then in a second it assumes that temperature, starts to grow. We watch it with a laser over a glass fibre optics. The laser measures the fluorescence of these samples. The fluorescence tells us about the amount of RNA produced. And when a certain amount was produced we stopped the reaction, take an aliquot out and start the next series... and Günther Strunk did this experiment.

In the first round, the experiment was a very simple one. We took a selection pressure... another enzyme, which degrades... which chops down the nucleic acid.  And this enzyme, so-called Ribonuclease T1, chops always at a G. It does not chop at other letters... I mentioned four letters, A, U, G, and C. Always chops at a G. So the system can evolve by simply hiding its Gs. So that the enzyme can't find it any more. And it can hide the Gs either by putting them into a base pair with a C, or by substituting the G by another letter, or by folding the molecule so that the enzyme doesn't have access. Well, Günther Strunk did this experiment. It took 70 minutes.  After 70 minutes we had a strain which was completely inert towards this enzyme. So it works wonderfully. This was an experiment which went on the way we thought of. And now comes the true experiment. We try to place a problem in such a way that we don't see an easy solution for it. And he did the experiment... nature found immediately, took again 70 minutes, found the solution.
What was the experiment? We took another ribonuclease, Ribonuclease A, and that chops at a pyrimidine. Now I told you before that in nucleic acids you have always a plus and a minus strand, a positive and a negative, and wherever you have a pyrimidine in the positive you have the purine in the negative. So it wouldn't help now to substitute the pyrimidines, or hide the pyrimidines or place them into base pairs, it would be just the wrong for the negative strand. Whatever you do for one strand is wrong for the other, and vice versa. So we said there shouldn't be any solution, but what will the system do? Well, before making big theories about it we did the experiment, and after 70 minutes we had a strand completely inert against this Ribonuclease A. So what happened?
Something like that happens, you do sequence analysis, you look at your product before and after the evolution. And we found something which we couldn't understand. Before the initial product had many, I think 30, positions at which the enzyme could cut and so no wonder that everything died out when you add the enzyme to the wild type, in both the plus and the minus strand. The final product which came out of evolution had in the plus strand no 'cut-able' region, everything substituted by purines, but all the vulnerable regions were now in the minus strand. How come? I mean, how can the system duplicate? The minus strand is necessary as an intermediate because minus makes plus and plus makes minus, so if you destroy one, the system is out. Well, we couldn't understand so we found out, let's do kinetic measurements, let's measure the rates by which it... and then we found a surprise. In the wild type, in the initial product, both strands replicate with the same rate; plus makes minus, minus makes plus.  Both with the same rate. That is in all wild types the optimal condition, and surely our system had adapted to it. Now the evolution product, there's a minus strand... is hundred times better than the plus strand. In other words the minus strand makes hundred times more plus strands than the plus strand makes minus strands. What is the result? You have hundred times more plus strand of the inefficient strand and hundred times less of the very efficient one, that's in daily life not very different. This really happened.
Now what does it mean? It makes hundred times more than the other. Well it means that the replicating enzyme binds a hundred times better to one strand than to the other. And now you see what happens; the efficient strand, which is present in low concentration, is always covered by the enzyme which does the replication. But the other, the inefficient strand which is present in large amount, cannot be covered and is vulnerable, so it got completely substituted. All the vulnerable strands got cut out and replaced by other strands. So within these 70 minutes of the experiments, two goals were reached. First of all in one strand all vulnerable regions were removed and secondly, in the other strand, it was made a hundred times better, more efficient, for the replicating enzyme than the other, so two independent goals. No one of us could have guessed this... could have calculated this. And you see, that's evolution, it's complexity in nature.  Nature finds a way not to calculate everything in detail, it simply replaces it by a number, namely that is fitness. And that's why it gets selected.

Before I started my theory in the '70s... the end of the '60s, I met Francis just accidentally in a hotel in Mainz... in the Hilton Hotel in Mainz. He'd just left that day, he had given a lecture the day before, and I was just arriving, we met at breakfast. So I told him about the theory and he said yes, he knows that Haldane, Fischer and Wright have done population genetic theories of this, and I looked it up and that was very helpful for me to develop the theory for molecules. But then when I came with the hypercycles, Francis said, 'Look, that's such a complicated system, I don't believe that. It's nice, it works, but you have to show that this really exists in nature'. One of the main things was, he had to do experiments that they exist in nature.

What does a hypercycle do? We said hypercycle links certain control units together to overcome error threshold, and secondly it solves the genotype/phenotype dichotomy. In other words you test your system at the phenotype and you must make sure that the phenotype tells the genotype, 'reproduce me'. And so, where could we find possibly a hypercycle? Well the best system again is a virus. In a virus, now... not a virus like Spiegelman did in vitro, that means in a test-tube, but the virus in vivo, in other words a virus infecting a host cell. And we took again our pet Q-beta, and Michael Gebinoga did this as a thesis.
What did he do? He took a coli culture and infected the coli culture with the phage, Q-beta, for certain amounts. This sample for one minute, the next sample for two minutes, up to forty minutes. After forty minutes the cells burst and about ten thousand viruses are sent out into the solution. So he did it... now he stopped the reaction when I said infected for one minute, it means he stops the reaction after a minute. Then he took these infected cells and he solved very carefully with phenol the outer membrane, the lipid membrane, and what is left is a ghost frame which can be penetrated by enzymes. And now he used these ghost cells and measured the kinetics using radioactive amino acids and radioactive building blocks for nucleic acids. He measured the protein synthesis and the nucleic acid synthesis. And then got the mechanism of it. And what came out are hypercyclic mechanism.
What does it mean? Well, I describe perhaps the mechanism of infection. Infection means one single nucleic acid molecule gets into the cell, through a pilus... the virus docks at such a pilus and injects its nucleic acid. Now you have one little nucleic acid molecule that is the virus genome in the host cell. The host cell has about ten to twenty thousand ribosomes, these are the machines which make protein synthesis. This little nucleic acid cannot reproduce, at least there are so many messenger molecules in the cells that it had no chance to reproduce. This virus has in its information the information for an enzyme which only replicates a virus, but for that you must translate, you must produce a phenotype of the enzyme. So what we found with our measurement, during the first ten minutes, only translation takes place. All these ribosomes in the cells, these protein factories, translate this one single molecule, one single RNA molecule.

The code protein has two functions, and another function which is much more important than being a code protein. The code protein binds to the RNA and stops the translation of the enzyme. So only during the first ten, twelve minutes you produce enzyme, and that means specific replicase, and after that it is stopped. Now what happens then? These produced replicases, these enzymes which can replicate now the virus RNA, now start to compete with the ribozymes in a hypercyclic fashion. In other words they make new RNA, the new RNA makes new protein and vice versa, and only those proteins feed back which are made from these.
Furthermore, you might ask why does the RNA production stop after that time. Well, it's the error rate. After that type, enough errors have accumulated that making even more enzyme now would make two erroneous ones and that would interfere with the real process. But during that short time between ten, twelve minutes, you now get a hyperbolic type of growth because at the same time it's not only replication which would make an exponential law, but at the same time the number of enzyme molecules increase also. So it's not only that you get two molecules, four, eight, sixteen RNA molecules; at the same time you make more and more enzyme and that's exactly what we calculated for a hypercycle until the enzyme molecules all are saturated. That's like a titration, then the reaction stops, and then with constant rate, according to the saturated enzymes, it produces for the rest of the time enough RNA molecules, enough proteins, in a very controlled way so that you have at the end for each RNA molecule the sufficient number of code proteins, so that you can form complete virus particles. Think... you make more nucleic acid than protein to code, then you get incompletely coded virus particles which would be immediately degraded, and so on. So it's a highly regulated system with promotion and inhibition, and the feedback is that you have a specific replicase which only replicates its virus RNA and doesn't touch any host RNA.
So we looked at this model, we calculated from the experiment and we found exactly the hypercycle fulfilled there. In other words, only a hypercyclic law, replication law, yields your hyperbolic growth laws, all the others would yield exponential laws and we could definitely prove that the law is not exponential but rather hyperbolic. In other words, it very slowly starts and suddenly almost goes to infinite, but it can't of course go to infinite, but a hyperbola has a singularity and that means where the goals would go to infinite. So hypercycle is a proven system.

Peter Schuster is the co-author of a book we have written, The Hypercycle - A Principle of Self-Organisation in Nature. Yes, I haven't talked too much about the theory because it's difficult. Peter Schuster is an excellent theoretician. These systems of differential equations are all non-linear. You cannot easily do transformations there, in other words you cannot easily get complete solutions. You can make phase diagrams, you can get attractors and you can show how the system behaves, but this is a highly theoretical work and I think I will come back to theory, and then I must also name another co-worker, that is John McAskill who came from Oxford to us, and who did renormalisation of the selection theory. There are lots of theoretical tricks and this is now a complete field of research... the molecular evolution.
[Q] So there is also evolution going on in your science? 
Oh, yes.

First was theory, I told you, and then there were experiments, we said we can't simply make theory. We have to find out that we do the right theory, or the relevant type of theory, and that we did by those experiments. And then we found, yes, we can even do theories for... experiments for things where you cannot do the theory. This evolution experiment, you cannot calculate it, the evolution tells you the system will find the optimal solution, and it did so, but the way how it did it nobody would have guessed before. So this established the technological principle, and now comes the third phase that we built machines for the purpose of using them for finding new substances and this is an entirely new phase in our work.
Before I get to this phase I should say perhaps a little more about theory... about Peter Schuster. I cannot introduce you into this theory of highly non-linear networks, but I can say what are the problems and what are the type of solutions we look for, and let's just start with that.
[Q] That's a good idea. But I would like to say the following. I have learned, being with you for more than thirty years, that you are a person, a scientist, who says, 'No theory without experiments, no experiments without theory'. So this just... that's your slogan for your science but this is... 
That's the way physics works.
[Q] Yes, but there are physicists who only concentrate on theory, and you combine it in a... I would say a very efficient way, otherwise the evolution... 
There was one great physicist who really placed the theory above everything, that was Albert Einstein. When Einstein founded general relativity there was no experimental... no proof... but there was no experimental evidence on which he could base his theory. It was made a theory out of his head, and it turned out to be a right theory. The special relativity, you could say there was the Michelson-Morley experiment which said that light velocity is independent of the system in which... so you cannot add velocity, the light velocity is an absolute way an upper limit of velocity and also that the light velocity was a limiting velocity came out of Maxwell's electromagnetic theory. So you could say, all right, for special relativity there were some hints - but still, I mean it... surprising results. Einstein made a theory of relativity to become independent of time and space and out came a relation like that mass is equivalent to energy and vice versa. And then in gravitation theory mass determines... bends the space, and causes light beams to be deflected by mass.
There was no experimental proof by then and it took quite some time and it turned out to be right. All other theories I think have been based on experimental facts. Think quantum mechanics, we had quantum theory, it was recognised by Planck and Einstein with his photoelectric law, that energy is quantized. But then people tried to understand the spectra and it didn't work. They knew there is a new theory which has to come and which has to be described and Heisenberg and Schrödinger independently found this new type of theory and it turned out to be equivalent to one another.

[Q] What was the necessity of your theory for hypercycles? There were experiments or facts which made it necessary that you make a theory which has got the name hypercycles? 
As I said genotype/phenotype dichotomy. I said first of all a theory without this translation, and that would get stuck with the error threshold. In order to overcome the error threshold you have to make good proteins. But in order to make proteins you need more information. So you got stuck somehow. So you needed something to overcome this. And the other is the fact that once you do translation you have to test your translation products, your phenotypes, but you have to store your information in the genotype and you have to make sure that you don't lose that, because otherwise everything is gone. So there was a necessity to... and there could well have been a different model. For instance, one model which we later on found and combined with the hypercycle, was that you have to make compartmentation. In other words, you know that all life is not in homogeneous solution, it's always in cells or in organism and so forth. So you'd have to compartmentalise your system of nucleic acids and proteins, but you might immediately ask: isn't it sufficient to compartment them, why then a hypercycle, now you keep protein and nucleic acids together in your compartment? Well, if you only would put them into a compartment, the nucleic acids would start to compete with one another, so you must fit them into a reaction network and that has to be cyclic.

Einstein didn't like quantum mechanics - until his end, his death, he did not really... he said, 'It's not the final theory', although now it turns out that so far it is the final theory. But Heisenberg insisted and said, 'Look, this is a theory which applies only to observables'. And Einstein said, 'Only theory can tell you what you have to observe and what not to observe'. So in other words he put the theory on top of it, while Heisenberg thought to find a theory which applies to observables.
[Q] So if I understand you right, Einstein put the theory as a motive for doing experiments? 
Yes, that's in every case, yes. But he said the theory comes first because only the theory tells you what type of experiments, what is worth to observe and how to interpret your...
[Q] Yes, but you can make a hypercycle out of this. Theory tells you what experiments to do, the experiments you have done, it makes maybe necessary... 
It has to be cyclic, yes.
[Q] To do theory to explain it, so the hypercycle. 
Yes, so we should name it after you!
[Q] So the hypercycle really was a necessity to come up due to the genotype/phenotype dichotomy to explain that or to overcome that problem.
Right.

[Q] You are known of having extended the Darwinian theory to molecules where it really becomes a physical theory. Would you please be so kind and go into that a little further, into that part of the theory? 
Yes, and I should immediately say that Peter Schuster was in that business right from the beginning.
[Q] Beginning is what year, about? 
Oh, beginning in the end of the '60s, I think 1968, 1969. At that time he was with me as a post-doctoral fellow and he was more interested in theory of hydrogen bonded systems and he was interested of course in relaxation measurements in hydrogen bonded systems. But being a good theoretician, he became interested in my ideas on evolution, and he offered me to do computer simulations.  And I remember in these early days we always... guessing in the morning what will be the outcome of an evolutionary problem and, well, who was right? The computer always was right, of course. But also John McCaskill, who came somewhat later then into the field, but he came from Oxford, he's Australian, and he did very important work also in theory.

Take a human population.  How would I differ from any other in that population? Could I quantify that? Could I say the difference between me and you or somebody else can be expressed by certain numbers? No we can't. In molecules we can. We can look at single mutants. In other words, we write down an equation for every single mutant regardless whether it is a fit one or whether it is a deleterious one. Each mutant comes into the theory with the same right so there is no preferred wild type. If you look at classical genetic theory, the emphasis was always on the wild type. Mutation was a perturbation term, which certainly was there and people know that not all species are genetically exactly identical, but in mathematics you couldn't specify anything and here you can do that quantitatively. You can immediately say, 'If this is the centre of gravity of the distribution, there will be the one error mutants... will be more frequent than the two error...', and you can write down the Poissonian distribution for those mutants now. So you can come up with a set of equations which finally make up the quasispecies. The wild type is somehow the centre of gravity in the quasispecies. It's not a special type in it. It sometimes even might be not the fittest type in the population, but being just in the centre means that it is somehow a consensus sequence of the total distribution.  And this leads to the concept of the quasispecies, which was absent in the classical theory. It also leads to the concept of the error threshold. You wouldn't get the error threshold... error threshold is not simply the length of the sequence and the... it depends on the fitness of each sequence which is weighted in this error threshold.

Now here we come to the fitness landscape.  The fitness landscape was an expression coined by Sewall Wright, one of the classical neo-Darwinian theorists. So we could ask again, 'What is new with fitness landscape?' Well fitness landscape was really seen as a landscape. Perhaps it's a good example. Let's look at the landscapes on earth. Think of an island. I think Benoit Mandelbrot has treated such an example in his book on fractals. Think of an island which is a mountainous countryside, and ask the question, 'How does a raindrop, falling on that island... will reach the ocean?' Well you would say, 'Well, it will run down wherever there is a gradient on mountains, but then it will soon be in a basin and the basin has to be filled up before the raindrops can go on in running down'. Now the picture you have is usually a one-dimensional picture. You see a cut through that landscape and you see it runs down, now fills up the basin, then it can run down further and so on. But our landscapes on earth are not one-dimensional. The surface of earth is two-dimensional, so a basin has certain heights in it and the raindrop will always come out at the lowest part. So if you take the one-dimensional cut through the landscape as an average, you don't have to fill the basin completely because a raindrop runs out at the lowest part of the rim of the basin, and therefore on average you don't have to fill it up. And now people have studied this if you go to higher dimension. If you go to a three-dimensional or four-dimensional, five, finally to a Hilbert space of almost infinite number of dimensions. That means the level can come lower and lower and lower and in the limit of the Hilbert space every raindrop will reach the ocean.

A sequence of nucleotides, if you talk about nucleic acids, has say N positions, N and a G in a thousand positions or whatever. If you write a sequence space then each position will define a dimension. In other words, if you are standing on a certain point you can migrate into N different directions, regarding... to the position which changes. Let's say you have a given sequence and now there is a change in the tenth position. Alright. You go in that dimension. Or there is a change in the 150th position. You go that way. So it's very similar as doing a mountain trip. What are you doing if you go on a mountain?
[Q] So I understand that using a landscape, a multi-dimensional landscape for what we have no real imagination is, so to speak, a analogy to explain the status of the nucleic acid. In the sense that you just say that... how big is the chance of having a mutant here and there? So it is just a transposition into another world to explain the complexity of a nucleic... is that right? 
That's correct. But you have to say in addition it doesn't need to be nucleic acid, but nucleic acid is something we can quantify... a sequence. We can exactly say which base is in that position, and we can compare to the other... is it the same or is it a different one? Now, the assumption behind it is that changing any of the bases will change the property of the molecule. Or later, if it is going to be translated into a protein, will change the property of the protein. Sometimes this will not change, then we talk about neutral mutants. So wherever you have some complex - and you had this in population genetics too, these were humans or animals or so - but you couldn't quantify it. But the properties are also consisting of many, many influences and elements and so, in order to describe them quantitatively you need high dimensional spaces. For each property you need a dimension. And that's exactly what happens if we do evolution, let's say, of a sequence of nucleic acids. We are in a high dimensional landscape, we need populations, that's very important, that's filling the basin with water droplets. If you have only one water molecule, nothing would happen, you must build up a population. The same is true with nucleic acids. Evolution without populations doesn't make sense, not a single molecule or a single entity doesn't evolve, a population evolves, and that this population is extended in space here means that it consists of many different mutants. And you see, if you have a sufficiently large population and you are in this high dimensional space, it's not so difficult to reach the next optimal step.

How could evolution have been so successful? I mean people always thought life is such a complicated phenomenon. Even the final stages of evolution, men... such complicated... how could it come about in the relatively short time of the existence of our planet? And then I can give you four results of the theory which say it's a little bit different from what you generally imagine. The first thing is you are working with populations, in which many mutants are present.  If you always would have the wild type and if mutation would be a little perturbation, well, you couldn't escape. You will see that later in virus infections. The virus is under the steady evolutionary pressure of the host system. The host develops an immune defence against the virus, so the virus must somehow escape it. It can only do it if it has sufficient mutations around. So, population means that you populate many mutational states.

The advantages... the progress of evolution if you adapt to new environmental conditions means that you have to look for new things, because within the quasispecies you have rated everything... evaluated everything. So if you look for new mutants, they will appear at the periphery of the quasispecies. Now what is the chance that you'd find a fit mutant? People always say, 'Well, the chance to have an advantage as a mutant is very, very low, almost all mutants are disadvantages'. That's true. But the disadvantageous mutants don't appear. Why not? Because you have this very far distributed population of mutants, so the distance from the centre of gravity of the distribution is many mutations... several mutations. So at the periphery any mutant does not appear by 'mis-copying' the wild type, that means the centre of gravity. It will appear by 'mis-copying' one of the mutants at the periphery. And those mutants which are almost as good as the wild type... as the average of it, as the... which are neutral, they are populated, like the... So in other words there is a rating within the quasispecies that the good mutants are populated... the neutral mutants are populated almost like the wild type, whereas the deleterious ones only are just formed and then disappear so they are present in very low population. So what you produce at the periphery are mutants of the good ones. And by similarity methods the probability that you get a better mutant from a good one is much larger than to get a better one from a bad one. So in other words, there is a very efficient way of testing for mutants, and we have studied this. In the experiment I have mentioned, within seventy minutes you got this completely different molecule which was able to resist to the degrading enzyme, and so how could you do that other in another way? The number of possible mutants there is astronomically high, but the system finds the right ones.  That's one of the important points.

How far do you have to go in sequence space? In other words, if you start at any point in the space, are you far away from the good one, from the roads which lead you up to the hill? I mentioned a mountain trip. If you want to climb on a mountain, how are you going to do it? Well, you go to a pass, and then follow a ridge. You don't go the walls up and down, you try to follow a ridge. The same must be true in the fitness landscape... the high-dimensional fitness landscape in sequence space. And the question is: how far are you from a ridge? Well, the answer is: the whole sequence space is caused by many ridges, and you don't have to go very far, then you get one where you can climb up. How did we know? Well, this a problem which had been studied by Peter Schuster in more detail, and I might perhaps tell a little bit about those explorations.
[Q] So you are now talking about how evolution found its almost direct way to the highest peak?
Right. Yes. Not getting stuck on a minor hill, yes.

To reach the highest mountain in Europe starting, let's say, from Hamburg. I choose Hamburg because it's a pretty low point, it's at the coast and no elevation. There are very minor hills near Hamburg, hills that are berg, which are perhaps 100 metres high also. If you do that in a landscape like the two-dimensional surface landscape of earth, you get stuck there, because in order to continue you would have to make a jump into the Hartz Mountains, to the Brocken. There you would be 1100 metre high or almost 1200 metre high. And I should say that I brought the example of the raindrop running downhill, evolution is a very similar... but we don't say evolution runs downhill, we say evolution runs uphill to the most fittest point. But the mechanics behind it, which you can form in mathematical equations, is a very similar one. So you... this theory all has been carried out and it's been shown. So here we have a mechanism... evolution, selection... provides you with a mechanism to go uphill wherever there's a gradient to go uphill. But if you are near Hamburg at these little hills here, you would have to make a jump of some 50 kilometres or even more to get to the next gradient, that means to the Hartz Mountains. And from the Hartz Mountains you would have to make also jumps of hundreds of kilometres to get to the next higher mountains, let's say to the Great Arber in Czechoslovakia. And from there you have to make another big jump to get to the Alps, and once you are in the Alps your jumpings might become a little bit shorter in order to reach finally the Mont Blanc.
So, in other words on a low dimensional landscape you would have to make very big jumps and the mutations would be too rare. So that's why people found it difficult to get this. Now Peter Schuster could show that in a high dimensional landscape that's very different. You always are close to some sizeable mountain from which you can go on, and if your population is large enough you can do so.

He treated it with an example, an example which you can treat quantitatively. He looked at nucleic acids, RNA, ribonucleic acids, and asked for the pairing of the molecules on the base pairing rules. You know, we have talked already about these building blocks of nucleic acids that they make positive and negative strands; in other words, the purine likes a given pyrimidine to pair with, the A with the U or T, the G with the C. And so he said, 'Given a random sequence, what is the chance... how much mutations do I have to introduce to make a completely paired molecule out of it?' That means that parts of the molecule must be complementary to one another. And he said that, 'I rate that as the highest fitness value'. That's something he could calculate.
And... now if you think of a molecule of lengths of 100... well, if you would have only two classes of building blocks then you would on average have to change 50 ones; in other words 50 ones you can take as given and for them you have to find the complementary ones. If you do that with nucleic acids you would have to change 75, you could only say that one quarter is the correct, the others you have to test. So you see that looks a very pretty difficult job, to find the best, in this case the best paired sequence. He found that what you have to do is to change on average 10 bases and you get there. So he developed the concept not only of a sequence space but also for a shape space. And you could go on and could say a shape space, if you look at proteins, the shape will determine a function of the protein molecule so you can have [define it as] a function space. And in order to get there you don't have to test all possibilities. Think of a molecule, a very small molecule of 100 bases. If you would have to test through them... through all possibilities, you have 4100 different sequences. 4100. That's 1060. So that's more molecules than you can accommodate on earth... on the surface on earth. So, if you would rely entirely on chance in testing those molecules, you would be lost, you wouldn't get there. But he found out that is not the case, you can do so and you can show that this is a way. He did computer experiments with it, and you see the progress, you get a mutant, and suddenly it stays for a long time and then it goes on again.
Now 'it stays for long time' does not mean nothing is happening in the population. We talked about neutral mutants, we talked about those at the periphery which are almost, or as good as, the in the centre of gravity. Well, this population fluctuates now. It might settle around one which formerly was on the periphery. You don't see that in the fitness landscape because it's neutral. So when it goes on again it's distribution has changed so much that the entirely new distribution came about in which progress again is possible. So in other words many things happen while you are on the same level due to neutral migration.
By the way, this is one aspect... also the population genetics theory has come about. Kimura has developed a theory of neutral mutations where he says that the main progress in evolution has been due to neutral mutants.

In the space of mutants, if I say space of mutants I mean the total amount of mutants, these 1060 possible if you talk of a length of hundreds, the 1060 different mutants are the space of mutants... among them there is not only one optimal molecule, there are many. And they are distributed in the space so that you don't have to go very far in order to reach the nearest optimal one which is nearest to you. If you do it on a different position you reach again an optimal one, almost, or as good as, or a little better, but it's an entirely different one. In other words the space is like... you see it already on the two dimensions on earth, there are not only high mountains in the Alps, there are even higher mountains or much higher mountains... Himalayas. And there are high mountains, the Andes, they also get into the 6000 metre range, and this is on entirely different points on the surface of earth. There is not only one biggest, one highest mountain; you are almost everywhere not too far from one of the most... and this is much more the case in high dimensional landscapes.

Selection is something like a phase transition at the error threshold, and you have similar problems as in solid state physics where you also talk about phase transitions and ferromagnetism and so on. If you go through theory you come to infinities, you come to singularities and so... so you have to do something which physicists nowadays call renormalisation of theory, and John McCaskill did this for this evolutionary theory I talked about. So he did the renormalisation and could show that you can solve all these problems, can get rid of infinities and... that's one aspect. The other aspect is he also looked at stochastic theory.  Why is stochastic theory important? At equilibrium, stochastic theory is not so important. Why? Because if you talk about a chemical equilibrium, given Avogadro's number  Avogradro's number of 1024  it means fluctuations go with the square root of that number. So one in 1012 is something nobody can measure. So fluctuation theory of equilibrium systems only is of importance if you are dealing really with only a few molecules. We will do so later, but generally what a chemist is doing, he always works with grams or milligrams and these are still a large number of molecules. That's due to the fact that you have fluctuations on the molecule level, but they average out, and then appear finally with the square root of the number of molecules and that's a very small relative fluctuation.
In evolutionary theory this is different. Let's say you get an advantageous mutant, just one molecule.  You have a big fluctuation for this to come about, you cannot predict it and everything on the molecular scale is probabilistic. So you have the very big fluctuation for this molecule to come about, but once it is there, and it is of advantage, it will double before it decays. So you have two of them, and the two will double before they decay, you have four, eight, and you get this exponential increase and now you see the fluctuation of that one molecule to appear will very soon map on the macroscopic scale, because of that amplification method. So stochastic theory is very important in evolutionary behaviour.
[Q] In explaining, also, evolutionary behaviour. 
Yes. At the beginning the favourable molecule can always decay, can just happen that right after it came about it is decomposed. But in this fluctuation theory shows that, like every air pilot knows, there is a point of no return when he accelerates his plane and if he reaches a certain speed he has to take off otherwise he would crash, he could not stop it any more. And so it is here, once after a few replications of a favourable molecule there is a point of no return and it will build up. And here you map your elementary phenomenon of one single molecule to come about, and one new one, if it is advantage, can do so, and that's very important to know, that otherwise evolution wouldn't be that efficient.

Let's go back again to experiments. I mentioned the experiment we did with our evolution machine, and there we found out a molecule which... well, which appeared to be  at least one strand of it  appeared to be completely inert against decomposition by a nuclease... by a decomposing enzyme. And the other molecule gaining efficiency for replication so that it is always covered by the replicating enzyme and thereby the system could escape the evolutionary pressure of degradation. Well, I didn't say at the time how the molecule looked like, but if you look at it then the original molecule might have consisted of about 150 nucleotides and the final molecule of only 90 or so... so there were big changes in the molecular structure, and just the right changes to produce it. So it's an incredible efficiency. I said a sequence of 100 molecules has 1060  one with 60 zeros  possible alternatives, and I picked out the right ones, within 70 minutes. So evolution is a quick process whenever the conditions are good.

Some years ago, I think quite long... almost twenty years ago... there were the first three-dimensional structures of protein molecule. Well the first, of course, was Max Perutz with haemoglobin and John Kendrew with myoglobin and they got the Nobel Prize for that. But very soon other molecules were looked at using the X-ray diffraction method, which was pioneered in Cambridge in the school of Bragg. And among them there was David Blow, that time in Cambridge, who determined the structure of a pancreatic enzyme, so that's trypsin and chymotrypsin. A pancreatic enzyme is an enzyme which is used in metabolism of food and in this very special case it's a protein which... it's an enzyme which degrades protein molecules, so it hydrolyses a peptide bond. Now the wonderful result he got from it was not only that he could determine each atom in this three-dimensional structure within an angstrom or a fraction of an angstrom precise, what came out is a great insight into the catalytic mechanism. The catalytic mechanism was to be a proton relay, in other words there was a spatial conformation of three amino acids, one being a proton donor. That was serine, it has an OH group so, where the proton can dissociate it will do so in the basic range, so at neutral it will be still the OH group but if you go up with your pH it will be an O- and the proton will come over. At the other end there was an aspartate, that is the carboxylic group like in acetic acid, so that is the proton of that group dissociates already in the acetic range, that means two pH values below neutrality or even three... two to three pH values. That means under neutrality where the enzymes work you have always the de-protonated carboxylic group  COO-. And here the protonated hydroxyl group, and in between there was a histidine which has an imidazole ring and the imidazole ring has two nitrogens, one being protonated, the other not. So... and its pKa is at 7, at neutrality. So, at neutrality you have either the imidazole ring protonated, and you have two protons and a plus charge on, so the hydroxyl group can give off its proton to the imidazole and the other proton of the imidazole hops to the carboxylic group. That's a proton relay, you shuffle forth and back protons and then you can make a very efficient acid base catalysis, because it's a hydrolytic reaction. And that makes the splitting of the protein bond, wonderful mechanism was known and very satisfactory.

There was another proteolytic enzyme from a micro-organism... from bacillus, subtilis, called subtilisin... the enzyme. It does about the same job as the pancreatic enzyme, the trypsin, chymotrypsin. But it turned out that it had no relationship to that enzyme, in other words it was an entirely different protein. The length of the polypeptide chain was different, the arrangement was very different. So there was... and if you make a... if you line up the two molecules you see they have no common similarities or so... they came about in evolution in quite different organisms. But they had to do the same job. And the surprising result was this subtilisin, being a completely different molecule, had exactly the same proton relay. Here, a serine, with its OH group, in between a histidine with its imidazole ring, and on the other hand the aspartate as a proton acceptor. So you see evolution, whenever it needed a certain function, realised it with quite different structures. That means in one case you were at that point in sequence space, and you don't have to go far to get your optimal enzyme, your chymotrypsin or your trypsin. In the other case you were at a very different point in sequence space and you got also the same optimal enzyme, the subtilisin, both utilising the same principle in nature.

In recent time, it was possible to make to make catalysts from antibodies. You know what antibodies are  antibodies are produced in our immune system to fight invaders... to fight invasion by foreign substances. So they are protein molecules of a different structure.  Much work has been done... actually we know it's about the best organ... we know how it functions... the immune system. And now some years ago Richard Lerner at the Scripps [Research] Institute at La Jolla and Peter Schultz at the University of California at Berkeley have used antibodies to make catalysts out of them. That's a very tricky way, because you have to think what does catalysis mean. Catalysis means you change a molecule. That means usually you have to bring it over some activation barrier. And on the top of the barrier, one calls that the transition state, the molecule has to get through this transition state in order to be... to be transformed, and the catalyst helps it to get over this activation barrier. Now the ingenious idea of Lerner and Schultz was to grow antibodies against transition states. Of course, transition state is not a stable state, so they had to use analogue states which had exactly the same structure as a transition state. And by growing antibodies  which is a procedure of a few weeks, to make antibodies  they were able to make pretty potent and efficient catalysts, by just using this trick, growing them against antibody analogues. And they did the same for making a proteolytic enzyme from antibodies, and here again you find the proton relay. So that is in the protein which evolved in the immune system, that means within a few weeks.
So you see, evolution doesn't need millions or billions of year. Whenever you have a clear problem given to the system, whenever you have optimal conditions, that you need in the immune system... Look, our mutation rate in humans is of the order of 10-12, so there's almost no change, otherwise we wouldn't be stable, we would simply disappear. Our genome contains three billion nucleotides, so if we copy our genome, that's from generation to generation, you have to be very precise with that and the error rate has been estimated to be as low as 10-12. But in the immune system you have to produce new substances, you have to optimise them, you have to get the best possible fit in the immune system, there you need high mutation rates and... César Milstein at Cambridge found out that indeed for the somatic mutation in the immune system, the mutation rates are as high as in viruses, so 10-3 to 10-4, and there you can within a short time adapt your proteins to a new job.

We have already talked about viruses, which are essentially genetic programmes which invade a host cell and then switch the host cell to reproduce a virus rather than itself  and in many cases this is the death of the host cell after some time. So from our knowledge of error rates and mutation rates and so on, we can draw two types of conclusion... well, in fact, we can draw three types of conclusion. We can study the evolution of viruses. We can see how did viruses come about. This question for instance in recent time was a very popular  how did the AIDS virus come about? Because it didn't appear in the Western World until 19... what was it?
[Q] '85.
...  or '85. So the question is where did it come from? Did it evolve that quickly, or is it an old virus, or what is its origin? So we can use our insights to tackle such questions. The next question is how can we detect viruses, very precisely, very sensitively? Because if we wait until we are swamped with viruses it's usually too late to do anything, and the earlier we can recognise an infection by a virus the better, the more we can do against it... so diagnostics. And the third problem is can we develop anti-viral strategies... can we try to use our insight in the variability of viruses to develop potent methods against the virus?
[Q] So you mean you use weapons of the virus to kill the virus by its own weapons... or strategies? 
 For instance, that's one possibility, and, yes, usually pharma try to do such things... to interfere with something which is otherwise a natural thing.

If you can make something which you cannot calculate, which you cannot even imagine, but you give a problem and let nature solve the problem via evolution pharmaca not via calculating because its much too complex for anybody to do such a calculation, but to find safely the optimal solution for the problem  that would be a wonderful principle in technology, to make new pharmaca, to make new proteins. To give you a practical example, often you will not make new proteins de novo, you will make them from other ones, as nature did so. The many enzymes which are in us were not all de novo inventions of nature, but whenever a new problem came it took one of the enzymes there and found which one is closest to it and optimised it for that special purpose. So there is... the whole complexity can only be explained this way. Now, we would do the same in technology. For instance we talked about proteases, enzymes which cut protein bonds, well if you have any napkin which is...
[Q] Has some egg from the breakfast on it? 
Yes, egg from breakfast, often some lipid or protein and so, now the industry is trying to develop enzymes which degrade this. Of course you would say... let's take the proteases... yes, but trypsin and chymotrypsin are proteins which work in our bodies, so their optimal temperature is 37°C. But in a washing machine, a laundry machine, works perhaps at 80°C and those enzymes would simply be decomposed at high temperature, so develop new enzymes which have their optimal temperature at 80°C, is a typical evolutionary problem. You cannot calculate what you have to do in order to make such a protein, you just adapt your system by evolutionary methods.
[Q] So the problem is to solve it in the way nature does just by very tricky tinkering. 
Yes.
[Q] You start out from a good position, and then... 
For instance, you take our evolution machine, as in the experiment I have described. But, of course, technology nowadays has much proceeded, so we can really consider it now a technological problem, and you might ask what do we have to do with our evolution experiments in order to make a technology out of it? I should say that we started very early...
[Q] What means early... what year? 
 Late '70s, early '80s, to propose this new technology. And meanwhile many laboratories have gone into the field, especially in the United States.
[Q] But proposing at that time meant also that experiments were successfully running at your laboratory? 
The experiments were successful and we say now we can go on and build machines, which are technological. But I should mention some of these laboratories in the United States: that's Jerry Joyce at The Scripps Institute is doing beautiful work there; Jack Szostak is doing wonderful work; Tuerk and Gold try to use a method for binding certain selection via binding to certain substances. So evolutionary technology is nowadays a...
[Q] A technology used worldwide...
A well established and cherished principle.

What you do is you introduce now all the successes in biochemical technologies into this field, and there are two possible... or several possible ones. First of all, we are able nowadays to amplify single molecules. Amplify let's say single RNA or DNA molecules. A Nobel Prize has been given for that discovery. There is the well known PCR method, PCR is an abbreviation for polymerase chain reaction. What is this polymerase chain reaction? Well, you simply mimic nature, and nature polymerises single RNA molecules, and we talked about the stochastic nature of evolutionary theory, from single mutants by an enzyme via a so-called polymerase. Now the trick of the PCR method is that a very special enzyme was chosen, namely an enzyme which can stand high temperatures. It was an enzyme from a thermophile microorganism. This microorganism you find in hot sources on the ground of oceans and so... and you can isolate the enzyme from those organisms here... aquaticus... therefore it's called Taq polymerase, Thermus aquaticus, T-a-q, and this enzyme has its optimum temperature above 70°C.
And now you make the following: you start with your sample which you want to amplify, you add to your system your building blocks for making nucleic acids, you have to make them from the energy-rich triphosphates, and you start with two primers. The primer is a sequence which is complementary to the sequence you want to amplify, and you need two because you need one for the plus strand and one for the minus strand. Now these primers bind at low temperature, so your first stage of the reaction is you're at 40°C. The primers... the two primers bind, one on the plus, one on the minus strand... and then you raise your temperature up to let's say 70°, 75°C, depending on what you are amplifying. Then the region between the two primers will be amplified. You make first two molecules of the one you have there is doubled, then you go up to above 90°C then they would come apart. Now you are back to the first stage, because now to the two molecules, primers will bind. You go to the optimal polymerisation temperature and again to 90°C... in each temperature cycle you double your number of molecules. So after two you have two, then four, then eight, sixteen, we had this before, and after thirty cycles you have 230, which is a billion molecules, and here you have now a macroscopic event.

There are other methods besides PCR, but PCR was the first method and it was Kary B Mullis who established it really, and got a Nobel Prize for it, although very important work in this field also was done in Gobind Khorana's laboratory. Now the other method... I perhaps should mention another one, which is called the 3SR method. I don't tell the abbreviation but I rather describe the method. You need three enzymes for the method, but that's not the 3SR, it does not refer to three enzymes. But what is it? It's first of all an isothermal method... you don't have to cyclise the temperature. Second, you start with the reverse transcriptase, that's the enzyme of the AIDS virus. That is able to transcribe the RNA back into DNA. You might remember that the dogma of molecular biology is that the information is in DNA, that's in a stable form there, that is transcribed into RNA where it's in a labile form and the RNA informs the protein factories, so that protein comes out of that DNA  RNA  protein.
But meanwhile one found an enzyme which can re-transcribe the RNA into DNA, and that's a whole class of viruses utilises this enzyme. They are called the retroviruses... utilises this enzyme to infect the cell, re-transcribe their RNA into DNA which then can be incorporated into the genome of the cell, though that's a very diabolic way of establishing the wrong genes in organisms. Yes, using this enzyme means that you start with an RNA molecule, you re-transcribe it into DNA, and then you take another enzyme, which is a so-called T7 polymerase, which means it is taken from a phage T7, and it is the polymerase which copies DNA and makes RNA. So you first re-transcribe the RNA into DNA, and now the polymerase comes and makes about one hundred RNA molecules from that DNA molecule. Now most of that RNA you decompose then by a nuclease, but before you decompose it you re-transcribe your amplified RNA into DNA and again each DNA makes one hundred RNA. You see while in the PCR reaction you make two, four, eight, sixteen, here you make 100 in the first step when the DNA is copied into RNA, in the next step you make 100 x 100, or perhaps a few less than that, and so you have a much steeper increase which for many of our methods turned out to be of advantage.
[Q] And the quality is the same? 
Yes. Yes, the quality is... well, it's even easier to handle because you can do all your work at 40°C, whereas the other you have to heat up to nearly the boiling point, to above 90°C. And there are more, even other, amplification methods, I will not go into all the details, but the existence of these amplification methods was important for our evolutionary technology.

I had described the serial transfer experiment with one sample. Now of course... why taking only one sample? We take a foil and make ninety-six, a microtiter plate, it has ninety-six samples. And these can be handled by the amplification techniques. Now we have three metal blocks with the three different temperatures and we move it from block to block so we can... we don't need Q-beta enzyme any more, we can amplify with the method and we can watch again with a fluorescence or some glass fibre optics to it... now ninety-six parallel channels. And, you know, when you start this the students become inventive. Meanwhile we have 960-channel method there. That means already our glass fibre optics are about 3km of glass fibres, but you see a real technology is coming out of it.
[Q] Big, large technology. 
Big technology, and that's what we had in mind from the beginning. As I say, many people now do work on evolutionary biotechnology, but it's a more pedestrian type of work than...
[Q] On a smaller scale. 
Yes, on a smaller scale.  And once you are at a 1000-channel machine you're starting to think how could you improve that to 100,000 or a million, which means you get into nanotechnology. You get into sampling very small sample amounts, which means size of microlitre or so. And that, of course, requires a very new technology, and this is really our present main job, to develop suitable methods for this nanotechnology. What are the problems? You could say also: where are the limits? Well, the limit is to detect a single molecule. And this idea, can we get down to single molecules, I had about a few years ago, and then I was remembering that one previous co-worker, a post-doc of mine, really meanwhile had pioneered a technology which was suitable for doing such studies. And I must tell a little bit more about that because it's our present main experimental work we are doing.

Rudolf Rigler was a student, had finished his thesis at the Karolinska Institute in Stockholm, and he met me when I got the Nobel Prize in '67 and asked whether he could come to Göttingen and do postdoctoral work with me. Of course he was invited to come, so he came, and there he had the idea to get down to small sizes... we have talked about fluctuations, we have said fluctuations go with the square root of the number of events you are watching. So he had the idea of looking at fluctuations, rather than on average values where the fluctuations are a small percentage of it. Look directly to the fluctuation.
There was a group in America also, it was in Professor Webb's laboratory at Cornell University. There were Magde and Elson, who also worked out a method which they called fluorescence correlation spectroscopy... and independently it was done in Stockholm by Rudolf Rigler, but the root was his time at Göttingen in the end of the '60s.  That was long before the other paper came out. He had the idea of looking at fluctuation... got together with Leo De Maeyer, whom I mentioned before, with whom we did the neutralisation kinetics. And Leo De Maeyer meanwhile has become a professor and has his own group and Leo and Rudolf went on to whether they could see the fluctuation style. For that they choose one of the very early lasers which became available, and they saw big fluctuations. Wonderful, but unfortunately it was a fluctuation of the laser light, so the lasers were not yet very stable. Simply, at that time technology wasn't yet ready for that. But Rudolf kept the problem in mind and developed it steadily when he returned to Stockholm, and worked out a method to determine the rotation of single molecules.

Now what is the trick of this method? I must perhaps try to explain that. First of all, you must choose a very small volume element. You have to... and, therefore, you need a laser. Only a laser with a coherent light you can focus into a small enough volume element.
[Q] What means 'small enough'?
Yes. Small. That's a good question. In our present work the volume element is almost a tenth of a femtolitre. Femtolitre is 10-15 litre, or what is better, a femtolitre is the size of a coli cell. That means about one micron in each direction. Three dimensions. One micron. And so we go to fractions of a micron. That volume is only a thousandth of an ordinary normal eukaryotic somatic cell also. So you can see it's smaller than the cells of living organisms, much smaller, and you could... even if you can do observations of such small volume elements, you can look inside a cell. So, that's what we do. In order to get there you need two technical improvements. One was the laser. Now present lasers are stable enough... we can focus them into that volume element and we can use the laser light for fluorescence measurements, I come to that. And second, you need good optics to focus it and that is called confocal optics.  And confocal optics was invented by Marvin Minsky... by the neuro... who works nowadays on theoretical neural networks and things he became known for.
[Q] Artificial intelligence, and things like that...
Things like that. But he invented the confocal optics in this work, and this is available now and companies like Zeiss build very good instruments with very corrected lenses and so... so that is no problem nowadays to focus light into such small volume element.

Why do we focus into a small volume element? Well, first of all, the noise will go down. The noise by light which is reflected and whatever comes in... scattering of light... so that, of course, would be very lethal if you want to see small fluctuations. But the second reason to take a small volume element is to make it so small that no molecule you want to observe is inside the volume element, it's simply too small for it... for having steadily one molecule present. As I said already, the property we want to observe is fluorescence. What is fluorescence? Well, fluorescence is a response of the molecule to electromagnetic radiation, so in other words you shine in light, quanta they are absorbed, the molecules get to an excited state, and emit again a photon when they fall back into their current state. Now of course the emitted photon has to have almost always less energy than the exciting light, so the fluorescence is always with respect to the exciting light... is shifted to longer wave lengths... but it's shifted far enough to longer wave lengths that you can easily record without seeing the reflections of the exciting light.

That's one thing, to pick up single molecules, that's fine, but if there are other molecules around...
[Q] If you want to look at the virus in the blood.
If you want to not only see single molecules but also seeing low concentrations. We will come to the virus later. I want to see a single virus particle in a millilitre of blood, or when I divide my thing it's only a few microlitre, and I want to see that... that particle. How can I do this? Well, a virus is a nucleic acid.  The genome of a virus is... the AIDS virus is an RNA molecule. So, I can make a primer. I have already said what a primer is... it's a sequence, let's say of twenty nucleotides... twenty monomers, which is complementary to a part of the sequence you are looking for, and since the AIDS virus sequences are known we can easily make such primers towards certain parts of the AIDS RNA... of the HIV RNA. So, those primers we can couple with the fluorescing group. In other words we put on a dye, a fluorescing dye. Now, there comes a problem. It turns out that you need at least a certain number of these primers for them to bind to the target... for those who know concentration values it's about nanomolar, 10-9 molar. If you go below with your primer concentration it wouldn't bind any more. Why not? Because the nucleic acid is folded, and it has to unfold in order to let the primer completely bind to it; and that folding is a internal first order reaction, the binding is a second order reaction combination with the molecule, and that needs a certain concentration to compete.
But what I want to do is I want to see a concentration much lower than 10-9 molar, I want to see a single virus particle. One virus particle per millilitre, well one virus particle per litre is about 10-24 molar, per millilitre is about 10-20, 10-21 molar, or one per microlitre is 10-18 molar. So I want to see when I divide my sample into microlitre probes into which I focus my laser light, I could see in fact concentrations as low as 10-18 molar, but they are a billion times as large as the primer concentration, and the primer of course contains a dye and fluorescence too.
So there are ways you have to use electric fields, you have to trap the molecule, you have to use different charges for the primer and the large molecule, there are now new polymers which are complementary which are called PNA. They are like are like RNA but have a peptide backbone which is not negatively charged. So you have to use all those tricks now to manipulate the single molecule in order to get them where you want to measure them. And that's a method which has been worked out, so that I can say nowadays we can use nanotechnology... we can manufacture technical devices in the range of micron... micrometre... where we can try to manipulate molecules using electric fields to carry them through and use laser beams which are focused into such a small area.

The sequencing... to determine the sequence of letters of building blocks in a nucleic acid is a very important problem nowadays. For instance for the human genome project. Now the difficulty is that you usually have many such molecules. If you degrade them, you have to do that step by step because of the stochasticity of the reaction. One molecule might go faster, the other goes a little slower, so if you want to see the sequence letter by letter by letter you have to do the first letter of all of them, then you have to stop the reaction. Then have to do the second letter, and that takes time. So a sequence velocity nowadays reaches in the best case some one thousand per day or a little more, and you have to... you can easily calculate what you have to do if you want to sequence one human genome. A human genome has three billion such nucleotides, and if you can do only a thousand per day you need three million days... that's impossible. Of course you can use many machines in parallel as people do, and you can use some tricks perhaps to get a little faster, but still with the present technology human genome project is a...
[Q] Very time consuming.
... time consuming, very involved procedure. Now, why not using again nature's technology? Use an enzyme which degrades the nucleic acid from the end, that's called an exonuclease, and pick up the single monomers when they appear in your focus of the... Because we have a method by which we can pick up single molecules and you know you can do that only with single molecules, because of the stochastic events and it would... If you would have ten molecules the first one would appear then, then the second one of the other molecule appears earlier than the other, so there soon would be a mesh of reactions. But with the single molecule they come step by step as they are degraded by the molecule, and now you can calculate.  The enzyme does a job in a hundredth of a second, and the day has 105 seconds, a hundred thousand seconds, so the principal limit would be ten million per day, which would mean in a hundred days you can do a human genome.
So we are working on this together with other groups because this is a high-tech problem in nanotechnology to machine those things, and we are working with people who produce these devices in nanotechnology, that's one possible application. But I mentioned it in here because that's where the limit is if you do evolutionary experiments, if you do... You have to come down to the sizes which nowadays are accessible to nanotechnology, you have to use analytical methods which can... that means you have to use fluctuation, correlation methods. But then you really reach a range in which you, well... in which you do molecular...
[Q] Single molecular...
... analysis. Single molecular. And now the consequences is not only biotechnology, you can develop now a molecular diagnostics for medicine... in other words you can really look at single virus particles, you can look at prions and, oh, lots of new words. So that's indeed something we are also very interested in and we do work on.

Viruses are not autonomous living beings. Viruses are, so to speak, molecule complexes. Are they alive? Well, outside a host they cannot live autonomously. In other words they need a host, they have to infect a cell and then use metabolism of the cell and so on and the machinery of the cell. So if the virus are outside of the cell you can crystallise them... they are just like inorganic material. But once the virus penetrates a cell it has all properties of a living being, be it already... Name some of these properties, it is able to reproduce itself, it will undergo mutation so it can adapt to a new environment, by having these properties it has the property of selection, Darwinian type of selection. Well, what about metabolism? Well, it utilises metabolism of the cell, it utilises the building blocks of... the cell also has to synthesise nucleic acids and proteins, so it utilises that. And sometimes it so efficiently reprograms the cell that the cell dies and the virus multiplies in large amount.
Now you might ask, where do viruses come from? Isn't it a principle against life which they are based on, if they destroy their host they destroy their basis of life also. That evolutionary adaptation is usually done the other way around, that you provide the basis for your existence and not destroy the basis of your existence. But viruses might not have learnt that and perhaps are able to learn because we have seen already they have a very high mutation rate.  They have the mutation rate which is simply the error rate of the polymerising enzyme which is of the order of one in ten thousand. So they make every... about every ten thousand replications they make one error, and if a virus contains ten thousand building blocks, well they make one per replication step. And that's how they build up a quasispecies of many different mutants.
Now we have studied very precisely the processes connected with it. Christof Biebricher using our [pet], the Q-beta, virus... phage Q-beta, has studied in detail the kinetics of these replication mechanisms and mutation processes and so on, and much of our knowledge is based on this. We also, and you yourself, were involved in this work. We also studied evolution of viruses. Now viruses most certainly are not prebiotic events, they are post-biotic events, because they need a host cell. So they can only come about when there is a cell, perhaps they were a part of the cell which got independent and used evolutionary tricks to become independent.

We can use viruses as models for evolution. In other words we can say well, in early prebiotic phases there has been a sufficiently rich environment in which complexes like the present viruses could reproduce and start evolution. That may be and that has to be shown if it is possible.  But the present viruses we have most certainly are somehow linked to their host, at least they cannot exist without the host. Now, to take the example of the AIDS virus, the HIV. You know that the HIV... the human immune deficiency virus so I look at the human and I compare it with the simian, that means monkey virus... specific virus. Now, in human virus we know at least two sub-types. People try to even to divide it further into sub-types, but there are two essential and very fatal types of viruses, that's the HIV-1 and the HIV-2, and they probably have a different origin. One looks more like having originated in central Africa, the other more in western Africa... the HIV-2... they have many relations, similarities, to the simian viruses.
Now the first question is: when did this virus occur? What is the evolution of the virus? Well, there have been many speculations about it because the virus in the Western world only appeared in the '80s. One thought: well, perhaps it's a new composition or something new. That question meanwhile is entirely clarified. Actually we did ourselves work and we used the method, you were involved in that, which we call statistical geometry. In other words, if you study those sequences which are evolved very far, which means which vary with the high mutation rate, you cannot use the classical methods of constructing trees, you have to... well, we have talked about the sequence space, you have to project the sequences into the sequence space and then look at their correlations among them.  And we have worked out a very potent method by which we can say we can study events which are very far back and distinguish it from events which appeared recently. So it's a more sophisticated technique which we also use for determining the age of the genetic code.

We have studied the AIDS viruses for simian and human viruses and there's one particular result which showed that the sequences we looked at seemed to have two regions of mutation. About 20% of the positions are almost constant. In all viruses we find they are the same, exactly agree completely, and moreover they agree with positions in other retroviruses which have nothing to do with AIDS... there are many retroviruses known nowadays. So that tells us that the evolution of the virus is that of an ordinary virus, it has a long history, coming along with the evolution of the species... in other words they belong to one big family of retroviruses. But that's only 20%. Then we find there are 70% of the positions which have a pretty long substitution time, on average a thousand years. In other words it takes a thousand years to substitute every of these positions, which still means after a thousand years you have a completely different virus because if you substitute all the positions, of course, you can only substitute by those which survive, which are fit enough.
[Q] Ten are left.
Yes. Now, yes, twenty and seventy is ninety, so 10%. And they are hypermutable.
[Q] 10%.
They change with the average time of thirty years, that's almost the incubation time of those diseases. And they are the troublemakers, because they cause the virus to escape the immune response. So the evolution of the virus is pretty well known, we find these... evolution in the 70% among simian HIV-1 and HIV-2. But within the HIV-1 group we have predominantly these recent mutations with a half-time of thirty years and, as I said, with the other viruses there are still 20% agreement. So we know pretty well about evolution, we have done that same for other viruses. Another one which evolves quite rapidly is influenza virus.
[Q] Just to go back, the result out of these calculations means the HIV is approximately how old?
The HIV in the form we find it nowadays has come about within the last thousand years, not longer than that. Before that it belonged to the family of retrovirus which have no symptoms like AIDS or don't cause symptoms like AIDS, which would mean also, it's an important finding. It would mean those viruses come and go, there might be other plagues coming up in the future... of viruses of which we don't know anything nowadays yet, and it might be that the AIDS virus after some time gets harmless again.

We can't wait for the virus to become adapted. We have to do something against them, and this is perhaps a good transition to talk about anti-viral strategies. All this work, of course, leads to certain proposals for treatment and colleagues of mine are working on this and we are at least trying to prepare some ground for it... some basis. I think of people like Esteban Domingo in Madrid with whom we co-operate.
What is anti-viral strategy? Of course, the most common is to interfere with the multiplication of the virus. In the case of AIDS this was for a long time the only way to treat patients, just to stop the replication of the RNA or DNA by... But of course such type of treatment is a very dangerous one because it stops also replication of the host cell's DNA. But in recent time, and that was already an early proposal, we came to say with such a large variability this virus has, adaptability, you have to see in advance the next steps the virus will do, so one has to study very carefully how will be the response of the virus, and one has to make sure in the treatment that you use several interferences at the same time which might leave the virus helpless and it might work. And the successes which were reported recently in the press about treatment of AIDS all are such combinations of several methods that they use, and proteases to inhibit the proteins, at the same time interfering with replication and so on. Now there is another type of treatment we could try to develop. We talk much about error threshold. Error threshold says that any replicating system, in order to keep its information stable, must be below the error threshold. It should be closed to the error threshold in order to be versatile and in order to be adaptable. But it must not exceed the error threshold. It's like exceeding a melting point, we could call it a melting point of information... the information will flow apart, and then it's gone. And one possible strategy in fighting viruses is to interfere with the replication mechanism in such a way that one perhaps finds substances that influence replicases or use replicases that are preferred in having a faster rate but making more mistakes, making so many mistakes that the virus...
[Q] Loses its pathogenic information.
Right. Loses its information and decomposes or whatever will be the consequence. But this would be an interesting way. Esteban Domingo in Madrid has tried that with some animal viruses, with foot and mouth disease virus. So at least he had shown in principle such a method works, you can deteriorate the virus by increasing the error rate. And you must also notice that error rate is not simply the number of mistakes you make and the length of the virus. It's also the fitness landscape... it's also that enters the error threshold relation, and that causes all the viruses to be different.

We have talked about the AIDS virus, apparently the most versatile one. It really has a high rate of mutation by which it escapes many interferences. A fairly high rate you find also with influenza virus. Peter Palese in New York has studied influenza virus and found that it has a pretty high rate of change which means that within many years the virus always gets different.
[Q] And that means that the vaccination of 1996 cannot cope with the virus of 1996.
Yes, the various proteins of the virus behave in a different way. Those proteins which are on the surface, so which are exposed to the immune system, change more rapidly than those which are inside the virus. But the rate of change is quite dramatic and one has not yet really looked for the variable, hypervariable and so there might be still a number of interesting details which could help us. You know that we can vaccinate against the flu, but it doesn't stay very long and has to be repeated because the virus changes so drastically. But again there are other viruses like polio where we have wonderful protection. The Sabin vaccine, the most popular, almost has eradicated polio at least within the Western world. Worldwide still it is a big plague.
[Q] I thought coming again. There was a time when one thought it was...
Of course, with increase of travelling there are no local diseases any more. Everything which is local in very short time will be spread all over the world.

Polio is interesting because there are some studies on sequences, and there is one interesting part is that the error rate in polio... not the error rate, the error rate is like influenza, it's of the same order of magnitude. But what is important is the acceptance of errors, in other words if you make errors and they are lethal then these die out and only the other ones remain. The question is how much error can the virus tolerate, and the acceptance of errors seems to be rather different in polio. We saw in those sequences we studied that only the third codon position really is changed. The first and second position, which determine the protein building block, the amino acid in the protein, those positions are almost unchanged. Whereas all the changes go into the third position which is redundancy and where they don't make much change in the protein structure. What does it mean? It means the proteins are pretty stable, so the immune system can get on target and can develop some defence. If the virus would change too rapidly, they couldn't do. But what is again... what is tested is the phenotype by the protein molecules. We don't know what the cause for this is. Of course the way of polio is a different one from influenza. You know, influenza gets through your breathing, little droplets of it, you know AIDS virus has to go through blood contact, or other liquids in the body have to be in direct contact, whereas polio has to go through the stomach. So these virus have quite different environment and react also quite different.

We have already talked how to detect single molecules. If you can detect single nucleic acid molecules you can detect single virus particles, and that would be very important to do that. We just have developed recently such a method, by a combination of the fluorescence correlation spectroscopy with the PCR technology, or we use the other amplification technology. What is the advantage of it? Well, first of all by using in the fluorescence correlation spectroscopy, using primers, which are only for the purpose of detecting the virus and therefore be very specific to the virus, you have no wrong, false positives or negatives.  You really... if there is a virus in there it will be detected by this. This is one very big advantage. The second advantage is that with this sensitive fluorescence technology, single molecule technology, you need only few replication rounds. So you can start... the more replication rounds you need the less precise is the technology because the enzyme somehow degrades and finally you don't get the amplification which you want, and for any quantitative method this would be very important, to know how many molecules did you amplify. Because, the most important use of these diagnostic techniques nowadays is not to detect for the first time the sickness, it's more when you get a treatment to detect the level of the virus, to find out whether the treatment helps and keeps the virus population down... the level down. And for that you need quantitative methods, you need... you have to say: alright, last week there were 'so-and-so' many viruses per litre of blood, this week there are 'so-and-so' many, and this is very important to do though. And the third advantage of this technology is all the present methods require quite a bit of ...
[Q] Material?
Not only material but also preparing the material, you have to make gels in order to find out whether your protein is in there or your nucleic acid which you look for. With the fluorescence you can really put your sample, your blood sample, with a mix, reaction mix, with your...
[Q] Cocktail?
Cocktail, yes, together into a plastic foil and seal it vacuum proof.
[Q] So it's also safety arguments.
Yes. And then you never have to open it again. You put it under your microscope, you run your amplification circles. All that goes automatically and you see under the microscope, like in a titration procedure, how your substance comes up. So it's much safer for mass tests, it's a much safer way to do so. This is technology we are trying to develop, and we have patents on that and we are co-operating also with industry on those projects.

It's a disease of the central nervous system and prions are the substances which cause this, but there was big surprise about the prions. Prions are not viruses, and it's almost certain now that there are no nucleic acids involved. Prions are protein molecules and most of the work... and the most important part of the work, has been done by Stan Prusiner in Berkeley in the United States and also by Charles Weissmann in Zurich and by Detlev Riesner in Dusseldorf. So what about the prions? Well, the prions are protein molecules. Alright, why not? Detlev Riesner in Dusseldorf, who is a former student of a student of mine, found out that there is almost... that he can pretty completely exclude the involvement of RNA, of nucleic acid. First of all, the infectious unit involves, I think, something like three hundred thousand molecules. So an infectious unit... it means that the protein as such is not very efficient but you need three hundred thousand whether the probability to find one among them is so low or whether you need a threshold - that has not yet been clarified. But the infectious unit involves many, many protein molecules and Detlev Riesner could show that in one infectious unit which involves many, many protein molecules there's less than one RNA of length of hundred base pairs. So that means there's no RNA. RNA can't play a major part in that.

Many people try to invoke nucleic acids because they can't think that anything could amplify autocatalytically without RNA, that simply isn't true. We know proteins which can amplify themselves autocatalytically, there's new work showing that this is possible. But the difference to nucleic acid is now inherent autocatalysis, in other words a very specific protein can be made so that it makes an important bond of itself and therefore can favour its own production. But that doesn't mean that every protein can do that, whereas nucleic acids, they all can act as templates and therefore they are inherently replicative. The same is true for more complex mechanisms. You could think of such mechanisms of protein favouring itself, but in this case that doesn't seem to be necessary because the most surprising finding is that the protein which does the infection is the protein you have in your cells... in your brain cells. So it's a normal substance your organism seems to need. Well, you can make now animals - mice - free of this and they still are alive, so it's not a very critical substance for living, but it seems to be... it will have some function. And the important point is this protein, this sequence... that means this gene, is your own gene, but one thinks that the conformation, the structure of the infectious protein is different from the host form... from the uninfectious host form. So what does it mean, different? Well the host form has lots of alpha helices, the spiral kind of structure, whereas the infectious form, the prion form as one calls it, has much more beta structures, they are strands leaning side by side, and therefore will behave differently in the cell. But one doesn't know what it is: is it just using up your host form and exhausting it, or is it a direct influence of the infectious form? But now you have the problem. Here is... you infect yourself with something which is identical in the primary structure, in the sequence of building blocks, with your own host protein. And this substance apparently manages to transform your form into the infectious form. We know such cases, we have talked about allosteric enzymes yesterday and we have talked about Koschland's mechanism of induced fit, so this would be a type of induced fit.  The protein imposes its form on the other. Also in the Monod model there was this 'all-or-none' transition from one conformation into another conformation. Apparently, that can be triggered. Now you refer to my theoretical paper on prions. I could show that one single subunit cannot do it. At least, what would come out if you would make a autocatalytic mechanism, using only one subunit, would mean that either we all get sick or none of us gets sick. What does it mean, get sick? If you get an infection it's important what is faster. The decomposition of what you get into the body, or the autocatalytic turnover of the other protein? Either one is faster or the other is faster. So, even if you get big infection, if the metabolic decomposition is faster than that it wouldn't harm you or, in the other case, if the autocatalytic conversion's faster everyone would get it. And I could calculate how little is needed for everyone to get it, and that those diseases come spontaneously shows that a very well-known disease like Creutzfeld-Jakob disease, and some others, have the same effect without being caused by an infectious agent, probably they are caused by some genetic defect so that the protein which has formed has a more likely a tendency to get over. But the incidence of those spontaneous diseases is very low. Creutzfeld-Jakob is, I think, one in a million cases, so it would not really be a big medical problem. Of course, who has it they wish we had a way of treating the disease, but it is not as is the BSE and a possible transfer of similar disease to men.

Your question: can we do something with our method in the case of prion diseases, would have implications also on Alzheimer, and we are at the moment interested in an early diagnosis. Now I said before that the disease cannot be triggered by single units, that came out of our paper. You need a co-operative, like in an allosteric enzyme, you need several subunits, or even a formation of little crystallites, so that you have a supersaturated solution and the infectious unit triggers that process of transformation. Well in both cases, what has been shown for the BSE is that you get plaque formation, very similar as in Alzheimer's disease. In other words there are decomposites of the protein in form of plaques which you can see under the microscope, and the co-operativity might well be connected with it. Be it as it may, it would yield us a very nice way of diagnosis, of early diagnosis, and that again is based on fluorescence correlation spectroscopy. But now we don't use the auto-correlation, we rather use cross-correlation and I must explain what I mean by that.
If you have a aggregate being the cause of the disease, then it means that several molecules have to get together, and when you can show that the infectious one does such a thing, then by proving the existence of these complexes you can very early diagnose the disease. And what we now do is we take two fluorescence dyes, and put one on part of the molecules and the other one on another part of the molecules, the non-infectious ones. Now in a case of non-infection these molecules remain separate and we see either the blue or the red fluorescence or the green fluorescence, but we see them separately. And what we do now is cross-correlation, that means we... you remember when I explained auto-correlation is that we measure products of intensities, an intensity at a given time, T, times the intensity at a moment afterwards, a T plus the other T. Now here we also measure products of intensity but not on time-scale. We now take intensity at a time T of the green fluorescence times the intensity at time T of the red. Now if they are separate, the molecules, these are independent quantities, and the product would be zero, apart from noise. But if they form a complex they fluoresce at the same time and then the product would be finite, and this method is very, very sensitive.  And this is always in a disease an important point to see it as early as possible and then start with some anti-viral strategy or anti-disease strategy.

The book was written in '75 already, it had over one hundred thousand copies in several editions, it has been translated in many languages, and so I think we brought over some of our general ideas. I remember very well that time when we said, 'Yes we have to say something, now we have to write a book'. And we didn't do any travelling that year, we really worked hard, and it was written in a time less than a year.
[Q] And the final title in the translation was Laws of the Game.
Yes, the English translation is The Laws of the Game. The German book was Das Spiel - The Game. Before we had written a smaller one which was called Ludus Vitalis and it has a subtitle How the Principles of Nature Govern Chance. One might perhaps say the principles don't govern chance but they govern the outcome of chance and control the outcome of chance. Well, the book starts with real games  you developed many of them  games played on a board, on a game board, and showing, so to speak, experimentally, the results of certain statistics.
[Q] It were not just games for fun, there was a deep background to show...
Right. Some games were made more for fun and others were made more for getting insight. There is this famous game from the turn of century, which was called the Ehrenfest model, which describes equilibrium systems. And this shows very nicely the fluctuations going with the square root of the number of chequers we use or, we used glass spheres so we had some relation to Hermann Hesse's Glass Bead Game, or what is Das Glasperlenspiel in German. And we played games of chance, true random board games but also games of evolution, selection, and showing not only the average result but also showing the fluctuations, the deviations, from the average. And all the games were played on a computer for many times so that we could make sure to have typical results.
[Q] For the typical results that the statistics was given.
Yes, but we did not stop with it. Here's the latest translation in English which came out last year again in Princeton University Press, and we applied the game. First we introduced a statistical game, we say 'the taming of chance'  then we brought games in time and space, structure formation, by dissipative forces, by Prigogine's theory. And then we talk about the limits of the games... the limits of humanity, we really come to the ethical problems of these applications which is games of growth. I mean that many of these games show that if you don't control the growth it might go beyond any limit, and our space and our resources are limited, and we talk about ecosystem and industrial society. And finally we get even to the realm of ideas, which means we discussed Popper, we discussed language, we discussed memory and, finally, art and music.

How do I see the difference between a complex system of chemical reactions  however complex you want it to be  many reactions going on forth and back, and a living system which, after all, is also a complex system of chemical reactions? Well, my answer usually is, in the living system everything is controlled and regulated, and the final source of this regulation is information. And this information really organises itself in a way that certain information is called off and certain reaction is triggered, and the whole thing then comes about in a very regulated way. Now, if you ask how did this come about; well, the complex states need information and information in order to come about needs replication, and without replication you can't build up the complexity which is reflected in information.
I'm aware that this is a very different definition one has given in information theory by Shannon and Wiener, where one is more concerned with the aspect of information capacity.  How much information could be expressed in language, how does a transmission line has to be designed in order to allow this amount of information to be transmitted without mistakes in a noise-free way? So these are the two aspects. One has always called the one aspect the quantitative aspect of information, the other the semantic aspect of information, but this is not a very correct type of expression. The one is really an information capacity, it tells you more about language than about any message in that language, whereas the other tells you why did certain messages come about. The messages have a meaning, that's semantics, but they have more than that. They are to be evaluated and the messages for life had to become evaluated... as we have seen, selection is a consequence of replication. Now, when you ask how did this transition occur from the non-life to life, then you certainly needed already a quite developed chemistry before life, the first steps of life, of forming information... it's language, forming in-for-mation... before they could occur. So the first reaction systems certainly were quite chaotic, were quite unregulated. And through this replication system there could be a build-up of information, and that's the essence of life.

Why do we do research? Well, we want to know, of course, and we want to know how this world functions and we... but that's not all. I think there is some gift we got in evolution, to be curious, so there's much curiosity in science. If you ask: why do we eat? Well, we have to eat, because it's necessary for our survival, we need the energy, otherwise our system would decay into equilibrium and that's like as Schrödinger told us already the state of death. So that we don't forget to eat, we have taste. We like to eat and some really are real gourmets. The same is true in science, there is some inner feeling that we have to know for our survival, otherwise we would be a short episode in evolution, and so there is some pressure, some tendency in us to do research... we want to know, we're curious. So that's I think also an important aspect and I talked about that.  And then I talked about the German university, yes, and about the many reforms and I think we have lost something. I think that the ideal of the Humboldt University was better than something we find nowadays in our German world. I think Humboldt's idea is better realised in the United States than it is in Germany now. The universities in the United States are very well organised along this scheme, which was first introduced by Humboldt.

Each has his speciality but that... you have to look for talents. You can't educate talents, you have to get the right people for the right job. Some are good scientists, some are good musicians, some are good artists, some are good engineers, some are good salesmen and we need all of them. But that's something you have to search for and your education system has to be designed accordingly. There was sometimes the idea you could learn everything. That's entirely wrong. 

I think it's the most urgent problem in the world... the population growth. We are now 5.7 billion people in this world. Roger Ravelle once calculated that this planet could at best feed 40 billion people if our...
[Q] ... demands for food would be lowered, in general.
Yes, if our demands for food would be lowered... not to eat too much meat, but to... that's a detour of the energy, of the free energy... and also if all the area in the world could be made as productive as the corn harvest in Iowa which is the highest yield you can think of. Well, I think we'll never get close to this stage when we use every bit of our planet for that, but you see how close we are to the limits and if you take our countries in Europe and some places in the United States locally we are populated as densely as if we would extend that over the whole world it would come up to 40 billion.  And we don't see yet how to get it under control, it grows and grows and grows and this would mean we would produce catastrophes with it. I looked at the growth law, it's even not exponential, it's hyperbolical, like in a hypercycle. What does it mean hyperbolic? It means it's not only a multiplication rate that children make children make children make children but at the same time more children reach an age where they can have children, that means the hygenic conditions, hygene conditions are becoming better, the food becomes better, the medication becomes better... but so even the periods of doubling shrink and shrink, it's not only... exponential all comes out of a constant doubling period, here the doubling periods shrink and shrink... so this is our problem. If we talk about environmental problems yes there are, of course, too many people and here we have to do a lot. We will need energy because energy is the only thing we almost could have an unlimited supply of if we really tried to make everything available. All the materials they are limited, they have to be circulated and... so these are problems and the question is if we look at the growth of our world in the last 50 years, if we think of what was brought about by communication, by computers, by ... we are not able to extrapolate what would happen in the next 50 years, what would happen in the next 500 years or... or larger times. If we go back 1000 years that was the time of Charlemagne if you would have asked him, 'What would happen in 1000 years?' I don't think he could have told you anything of what happened in fact.

An exponential curve never goes to infinity, it go only up to infinite time. But the hyperbole has a finite time... infinity. When I told this once in Jerusalem, in a lecture, the Jerusalem Post next day said, 'Scientist predicts the end of our world in the year 2041', because this hyperbole I calculated has a singularity at 2041. Well, my reply was, 'Exactly that I did not say, because in our world nothing can get infinite'. What it means... the only thing I can predict, that we will not reach infinity at any finite time. But on the other hand, if we are close to a singularity we'll get fluctuations and only by those fluctuations, and they will become larger and larger, we will prevent infinity. And we see that already, we have catastrophes in the world and to look at Africa or other places in the world, it is really something we should think about. And this is an unsolved problem, and I don't think you can solve the problem without science. In other words many people come to the conclusion saying well, we have done too much in science and that caused all this trouble to us. That's not true, that's not true. Only with science we can prevent trouble. We are so dependent on civilisation now that without it, that would be the end.

The title of the book will be something like Treatise on Matter, Information, Life and Thought. Some friends say, 'Why don't you tell us what you will not cover in your book? It seems to be everything!' Indeed I'll start with physics, and the first chapter is Energy and matter, and we will show... we'll get into physics, into relativity, quantum mechanics, elementary particle. But I do it in order to show what are the laws of physics, what kind of problems are we dealing with. And if I would express it in one word, we try to generalise our theories, to become universal more and more, so that it is a trend towards simplicity... but it's a strange simplicity, it's a simplicity we have no imagination for any more. We don't understand. Look at Einstein's field equation.  It's very simple, beautifully symmetrical equation there, but these are [unclear]... and they have properties we don't meet in our daily lives. So the theories, by getting more universal, more symmetrical, more simple, get stranger and stranger and stranger. Now I introduce another complexity with entropy.  The next chapter is Matter and entropy and then Entropy and information, and Information and complexity. And there we need self-organisation and so Complexity and self-organisation, that's before I can get to Life and thought. But if I again express life and thought, then it gets utterly complicate, complex, but it's a familiar complexity. We don't think that if a couple has children that... we think this is a natural phenomenon and everyone accepts it as a given fact. But if you try scientifically to understand what has to happen in order to copy your genes with three billion letters and do it to make sure that you get the right mixture of genes from your mother and your father and that everything like that comes about, that the cells differentiate and so on. This is utterly complex, and biology in contrast to physics, is this science of this complexity, but with outcomes which we meet in our daily life, for which we have the experience.
So, I want to contrast these two problems which then continues in culture, and the last chapter is Culture and the future. So, I say this because there were several attempts of the physicists to understand life. The first famous book was Schrödinger's What is Life?, and there was always the physical thinking that, as if life would be a special state of matter, and as if you could understand it by understanding the structure of life. No, no, life is a dynamical system, life is something which happens, life cannot be understood by the structures alone. Of course, life is built on physical substrates, and physical substrates have structures and so they are involved and their particular properties come in. But the whole is a dynamical system far from equilibrium as we have seen already, and I try to get this ideas into the book.

Of course, you have to make decisions, whether you want to be a statesman, politician, or scientist, an artist.  You can't do everything and you have to do what you do, you have to do carefully and as well as possible. So there were often the questions whether I take over a presidency of a larger organisation... including the Max Planck Society and others... and I said, 'No, this is not my goal in my life, and I'm not a born president of a larger organisation'. I realise that Einstein thought along the same way. After the war they asked him to become the President of Israel and he said, 'No that's not my business. I'm a scientist and I will go on and do...' And that's a little bit my credo. But, of course, you have duties towards society. So I thought I looked for certain positions which I ought to do, where I think I have to pay something to society, and one was the Studienstiftung. The Studienstiftung is an organisation in Germany which furthers gifted young people in both arts and sciences. In the arts, in music, in painting, in sculpture and in all the sciences including humanities. So, they must really be top people, they must be real talents. And then they are funded and one helps them also to produce a thesis and so on. And I thought this was some task for me, that I had to do something in that. The money we spend is about thirty, forty million per year, it might now have increased. I retired from that post when I retired from my scientific career. But I thought here I can do something to society, furthering young talents, furthering young people, and I must say it was a very satisfactory arrangement. I had to talk to ministers and make sure that the support was given, but so far it worked out. This is one of the... of course I did also some obligations in science organisation. I mentioned already that I took over the presidency of the European Molecular Biology Organisation.

Molecular biology... we all call ourselves molecular biologists. And that already led to some criticism by Chargaff, where he called it, 'One with licence and without licence'. And he thought that Crick and Watson didn't have a licence but he himself did have one. I heard an even nicer story about molecular biology recently by Charles Weissmann. I'm sure he heard it from someone else so I don't know who is the really originator. There is a man walking around in the landscape and meeting to a shepherd, and he went to the herd and said, 'Well, you have beautiful animals, they are incredible... what kind?' And he said, 'If I could tell you in ten seconds how many animals you have in your herd, would you give me one?' The shepherd said, 'Yes, why not? If you can do that in ten seconds I will give you one'. So he looked around and after five seconds he said, 'Eight hundred and twenty three'. The shepherd said, 'That's true, how did you do that? Well, take an animal'. So the man took one and was about to go and the shepherd said, 'Wait a minute, if I could tell you what's your profession, would you give back the animal?' The man said, 'Yes, why not? Sure, sure'. He said, 'You are a molecular biologist'. The man said, 'How did you know? That's true, yes, how could you find out? You must tell me'. The shepherd said, 'Yes, I will tell you, but first you give me back my dog'.
OK. So, it's not that bad with molecular biologists, at least they have learnt to handle pets like bacteria first, viruses, and now also molecular biology is dealing with mice and... OK.

We are fortunately coming now to an age again where people think that the insight in science should really be made available to society via applications. There was a time where this was not so. For every new discovery they asked, 'What danger does it bring about?' They didn't ask what is the utility... the use, for mankind. Now, we made in our work on biotechnology... I mentioned already that evolution forms a basis, a principle, a new principle, for a new technology, which I call evolutionary technology in contrast to the classical biotechnology which is a conservative technology. What does it mean, conservative? It comes from the Latin word 'conservar', that means maintain. And as you see in the classical biotechnology, everything is maintained. You use a gene, let's say a human gene for insulin. You want to make insulin and you use it from human, so you have not invented this gene, nature has invented it. But you use it, you maintain it, you conserve it. And then you put this gene into a coli cell, via a plasmid and so. So you use the production machinery of nature, you don't change this machinery, nature has invented it, you conserve it and let it produce. So the only artificial thing you do is that you plant a human gene into a micro-organism which is better in producing the material and which you have to make sure that the micro-organism doesn't throw it away because it is of no use for the micro-organism, we want to use the insulin produced by it. But this is very important for... and there are many other processes now in pharmacology where you can produce most natural pharmaca in order... by this technology. And we, for change, call our technology an evolutionary technology. You don't have to conserve your gene, you let it evolve. You might start with a given gene and produce, but you don't have to produce it de novo. And you don't need a animal or a organism to produce what nature has produced, you built a machine which you invent and optimise for your purposes. And I think that the future in biotechnology certainly will be a combination of the two. And we thought we should introduce this into technology, and you yourself were involved too with some colleagues together with several scientists. Some years ago we founded the company Evotec in Hamburg. We were fortunate to find somebody to give the money for it and the company is developing quite well, has now eighty employees already and so this is also, as I considered, a service for society.
[Q] And it took over the people out of your evolution school, so to speak.
Yes, it gave them a job, which in our days is an important thing. There are many people which do not have a job.  And it's even a job which could be a profession... where they can... their professionality... where they can use what they learnt.

I give many lectures, public lectures, on many subjects... general subjects and scientific subjects... and I must tell you I like it. I like to give lectures and I have the feeling that people like it too.
[Q] Yes, I have the feeling that the audience likes it too, because your lecture hall always are filled... very filled.
And also we organise seminars and even there's time for hobbies. What hobbies? Well, music I mentioned already. There was a time where I did quite a bit, where I practised in order to perform publicly... concert, and at the moment I don't have time because writing the book, organising the company, and organising the group, that's too much. So I hope when I'm through with the book that I come back to... and I know already what I will practise then. But I also had some sports I like. A friend, Hans Frauenfelder, a physicist, now in Los Alamos after his retirement, is Swiss-born. All Swiss-born physicists are good mountaineers, so we went climbing mountains, even our two sons. So, his son, Uli, and my son, Gerald, they both are professors now, Uli for linguistics and Gerald for elementary particle physics... they both came along and it was always who's fastest, the two sons or the two old-timers? And I think we did very well, and we climbed up to the fifth degree, it was quite... with rope, and...
[Q] And your daughter, did she join you?
Angela? No, Angela is more for the practical things. She's organising in a firm the foreign part in east Asia, so she learnt languages, that's her hobby. She is more like her mother... practical.

It was in 1965 that we... actually the two of us was together with some friends... thought we should have a seminar with our co-workers, not with others, and we should go away from the lab because in the lab you have your daily life here and... we should really go to some nice silent place and... since there are so many meetings in summertime we say, 'Let's have a winter seminar and let's discuss there our problems and if we have time left, let's go skiing'. That's how it started. And it was a very little farmer's house in Austria...
[Q] In Austria, in Brand, in Vorarlberg.
Yes, but how many people were we?
[Q] At that time maybe twenty. But the main thing was that those who had never had a good chance to talk with you uninterrupted of telephone or whatever, to talk with you about their scientific problems; be it a diploma, be it a thesis. So it was the ideal frame... 
Not only that, also vice versa. I had the time to talk to them and learnt from my co-workers what they have done and what they found out. And I remember that... that was a time, the '60s, where our lab was already flooded with foreign guests, and we talked about the fast reaction work. And so these foreign guests came along and told their colleagues and so after a few times the number of people participating in the winter seminar increased and increased.
[Q] And also the international...
You remember Hans Sachow [sic] came along?
[Q] And it also internationally was growing. 
Yes, right.
[Q] So if there was a professor for a sabbatical leave in your institute he would participate, he would contribute with a lecture. So it really spread out like a tree with very many arms, so it became very international. 
It almost became an institution, an international institution. After a few years it was fixed seminar, and then people from other universities came. And I think if you ask how many Nobel Prize winners have talked at our winter seminar, I think the number is between thirty and fifty somewhere. And many of them got their Nobel Prize afterwards. So in other words we were able to interest people who are still very active and doing their work.

I hated, if I get invited to a meeting, and first I say, 'Oh yes, that's an interesting subject'. And the next is, 'You have to provide an abstract and till then and then ... And you have to come with your manuscript', then already I say I can't go every month or every week to a meeting and then write a manuscript, otherwise I wouldn't do anything but writing manuscripts. This winter seminar doesn't require any written text. And the point we stimulate people to talk about work which is not yet finished, so which can be discussed still. In other words, people are uninhibited to talk things, because they are not pinned down, they can speculate in the seminar. And that makes it lively, that is the... And great people come now to the winter seminar. You don't have to take our thirtieth winter seminar where we had people like John Wheeler, Steven Weinberg and many... Roger Penrose, and many famous biologists.
Also many new ideas came out of the winter seminar. The first winter seminars we were concerned with macromolecular structures, with helix coil transitions, protein confirmation, allosterism, that all was discussed at the winter seminar. New ideas came there. Then enzyme kinetics, then the question of the origin of life and the evolution... evolutionary theory. These were ideas which were heavily discussed at those seminars, and many new papers came out of it. That continued with discussions of cell differentiation, of questions from embryology. It went on to the central nervous system. I remember several times David Ubell [sic] came and gave inspiring talks and we had theoreticians, Christopher Nomaltz [sic], Jack Cowan. And I think it was a meeting... I wouldn't know any example, it was unique, it was very unique... and the people who once participated were enthusiastic about it.

It started with fast reactions, yes. I mean, I had some problems which I solved before that, but I was really a child still. Now, of course, many co-workers joined me and I really must say now it was always a great pleasure to co-operate with other people, and I never remember that we had a bad atmosphere here, it was always in wonderful way to work together. Many of them became professors there. One of my first students was Gunther Von Bünow, he's now also emeritus already; Gerhard Schwartz, who will be emeritus next year or in a few years; then George Czerlinski, Hartmut Diebler, Kaspar Kirschner, Georg Ilgenfritz and many others. I think you know them.
[Q] Yes, there are some names like Günter Maass, just to mention, and then Eberhard Neumann...
Eberhard Neumann came finally also.
[Q] Friedemann Schneider...
Friedemann Schneider. And many American colleagues and English colleagues... David Hague. And we had Claude Bernasconi who's Swiss, who wrote a book on fast reactions in organic chemistry, and Gordon Hammes, Ken Kustin, Ted Eyring...
[Q] Don Crothers.
Don Crothers, yes, there are many, many... and not only postdocs, many colleagues came and I remember that Al Lehninger spent a year with us, Buzz Baldwin also, he came from the Stanford group. And many colleagues are visiting, like Lars Onsager came for a semester, Peter Debye came as a Gauss Professor to Göttingen, Arthur Kornberg visited, Britton Chance, Hugo Theorell... you remember we played...  Hugo was a violinist and his wife, Margit, was a cembalist [harpsichordist], a professional cembalist. And I played four hands with her, and we played trios and quartets and, at the place where you live now, at Schloss Berlepsch, in the Count of Berlepsch and his wife were both also violinists and viola, and we never stopped before four o'clock or five o'clock in the morning, so it was real lively atmosphere, triggered by scientists. Other people came, like Fitzi Lynen, from... famous biochemist of Munich, or Gentner, Fritz Lipmann...
[Q] Max Delbrück...
Max Delbrück yes.
[Q] John Eccles. But there you get into a very long list.
Yes, but if you now review that back then you say what wonderful life that was and what wonderful to work with nice people in a good atmosphere and having interesting questions to discuss.

There was a few papers of mine got into the... got a high ranking in the science citation index, and they have a special journal that if a paper ranks very high in that they ask you to write a little sketch on how you came about to write this paper and how you did with it. And they asked me... they had two papers. One was in 1971 Naturwissenschaften paper, that's about life, origin of life. The name of the paper was Self-organisation of matter and the evolution of biological macromolecules, and the other was a paper written a few years earlier. It say, Proton transfer, acid base catalysis and enzymic hydrolysis. So a paper on the fast reaction and here on the slow reaction of evolution. They say, 'What is the connection between the two areas?' And I said, 'Yes, there's a very close connection'. We studied reactions. We studied simple reactions so we know what is possible, so we know that... not only what is possible. We also know what is not possible. In other words, how fast can a reaction be? And then we say, 'Is there anything in the living material which is... cannot be explained...which is mystical?' And the answer was, 'No'. The reactions go as well as they could go but they never do more than that. They are optimised, but we can understand where the optimal limits are and they reached it, but not more.

What is life? It's not so much the question, how did life come about on our planet? That's a historical question. In order to find out how life originated on earth you have to have witnesses, and you have to... and since this time precedes the geological witnesses there is not much we can do. So the questions we can really answer is: how is it possible that something like life can come about? So in our case life is not the historical process which took place. Life is a principle. Life is some behaviour of matter and many people have asked that question: what type of behaviour of matter is it? What is life?
Well, first of all we see life now as being represented by the living beings, and there is a huge multiplicity of different living beings. And to subsume them under one word, namely the word 'life', wouldn't give you much information about what life really is. If you know everything about coli, what do we know about man? So we asked more the question: what are the principles? What has to be fulfilled? What has to come about? And we see it's not so much the structures you find there. Of course, I said life is formed on structures, therefore I am not a believer in simulation of life by computers. Why not? Because the computer only does what you program it for. In other words, if I want to program life in a computer, I must program the whole physics and chemistry in it. Because life takes care of those things, life makes... takes advantage of the structures being present. And if the computer will tell you about how really the systems that evolve look like, you must program that all into the... But you can do much more by doing experiments on it, or doing very directed experiments, to ask certain questions.
[Q] I call that 'if then' questions.
Yes.
[Q] If you have this random circumstance, these random conditions, then the system will behave... 
That's all we can do in science, that's all we can do in physics too, given that... what follows from it. We can't ask for the principal causes, for the first causes, and I think the biggest mistakes which have been made were to ask such questions. Rather than to find out what really happens, what follows from what and what has to be fulfilled in order that something like that comes. So life to us appears to be a dynamical process. There's no evolution of single individuals. Evolution is the property of populations, so life as a whole thing evolves... up to humans.

It's a game... it's a game of chance and necessity, as Jacques Monod correctly phrased it. Jacques thought a little bit more highly about the chance, we perhaps might lean a little bit more on necessity. But it's certainly a interplay of chance and necessity. And what can we take out of it, what is our role in the game? We are observers of the game, and we are participants, and we have to contribute our part. We cannot contribute any more to evolution, it's much too slow on the level of a genome which comprises three billion nucleotides. But everything what happens now doesn't happen on the level of genes. It happens on the level of our brains, and here we are right at the beginning. We are thinking of individuals as humans but we don't yet think as the humankind, and we are in the very early stages of our evolution. As I say, it's completely on the level of mind and brain, and we are not very far proceeded. Look, the people shoot on each other and kill each other as they have done ten thousand years ago, and... or a thousand years or two thousand years ago. What did they learn by that? And, it's really time that we bring the evolution on to this level, and the goal of evolution is not man as such, it is mankind.
